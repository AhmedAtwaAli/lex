{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Scraping data for the Lex Fridman Podcast**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: youtube_transcript_api in /opt/miniconda3/envs/minimal_ds/lib/python3.12/site-packages (0.6.2)\n",
      "Requirement already satisfied: requests in /opt/miniconda3/envs/minimal_ds/lib/python3.12/site-packages (from youtube_transcript_api) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/minimal_ds/lib/python3.12/site-packages (from requests->youtube_transcript_api) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/minimal_ds/lib/python3.12/site-packages (from requests->youtube_transcript_api) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/minimal_ds/lib/python3.12/site-packages (from requests->youtube_transcript_api) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/minimal_ds/lib/python3.12/site-packages (from requests->youtube_transcript_api) (2023.11.17)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install youtube_transcript_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from collections import Counter\n",
    "import time\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get video data using BeautifulSoup and YouTube's Data API v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This scraping operation took 4 seconds\n"
     ]
    }
   ],
   "source": [
    "# Record start time for performance measurement\n",
    "start = time.time()\n",
    "\n",
    "# Create empty lists to store video data\n",
    "videos_id = []\n",
    "videos_title = []\n",
    "videos_description = []\n",
    "videos_upload_date = []\n",
    "videos_duration = []\n",
    "videos_views = []\n",
    "videos_likes = []\n",
    "videos_comments = []\n",
    "videos_tags = []\n",
    "top_ten_words = []\n",
    "videos_thumbnail = []\n",
    "videos_favorite_count = []\n",
    "videos_region_restriction = []\n",
    "videos_captions = []\n",
    "videos_captions_text = []\n",
    "\n",
    "\n",
    "# Fetch the Lex Fridman Podcast webpage to get only the episodes' links to use in the youtube API endpoint \n",
    "# as there are other links in the page that are not episodes videos\n",
    "bs_response = requests.get('https://lexfridman.com/podcast/')\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(bs_response.text, 'html.parser')\n",
    "\n",
    "# Extract all YouTube video URLs from the page\n",
    "youtube_urls = []\n",
    "for urls in soup.select('div.vid-materials'):\n",
    "  url = urls\n",
    "  youtube_urls.append(url.a.get('href'))\n",
    "\n",
    "# Process YouTube URLs in chunks of 50 for API efficiency (youtube api doesn't allow for more than 50 API calls in one API endpoint)\n",
    "for i in range(0, len(youtube_urls), 50):\n",
    "  youtube_urls_chunk = youtube_urls[i:i+50]\n",
    "  # Extract video IDs from the URLs for the YouTube API\n",
    "  video_ids = [url_ids.split('v=')[-1] for url_ids in youtube_urls_chunk]\n",
    "\n",
    "  # Construct YouTube API endpoint URL\n",
    "  api_endpoint = f\"https://www.googleapis.com/youtube/v3/videos?part=snippet,contentDetails,statistics&id={','.join(video_ids)}&key=AIzaSyA087wwY7-mxbqeER7UXqbm8nJbHPQpm5M\"\n",
    "  \n",
    "  # Make youtube API request\n",
    "  yt_response = requests.get(api_endpoint)\n",
    "\n",
    "  # Parse the JSON response\n",
    "  data = json.loads(yt_response.text)\n",
    "\n",
    "  # Iterate over the data json file to get the required data\n",
    "  for item in data['items']:\n",
    "    video_id = item['id']\n",
    "    video_title = item['snippet']['title']\n",
    "    video_description = item['snippet']['description']\n",
    "    video_upload_date = item['snippet']['publishedAt']\n",
    "    video_duration = item['contentDetails']['duration']\n",
    "    video_views = item['statistics']['viewCount']\n",
    "    video_likes = item['statistics']['likeCount']\n",
    "    video_comments = item['statistics']['commentCount']\n",
    "    if 'tags' in item['snippet']:\n",
    "      video_tags = item['snippet']['tags']\n",
    "    else:\n",
    "      video_tags = None\n",
    "    video_thumbnail = item['snippet']['thumbnails']['high']['url']\n",
    "    video_favorite_count = item['statistics']['favoriteCount']\n",
    "    if 'regionRestriction' in item['contentDetails']:\n",
    "      video_region_restriction = item['contentDetails']['regionRestriction']\n",
    "    else:\n",
    "      video_region_restriction = None\n",
    "    video_caption = item['contentDetails']['caption']\n",
    "    \n",
    "    # Append data to respective lists\n",
    "    videos_id.append(video_id)\n",
    "    videos_title.append(video_title)\n",
    "    videos_description.append(video_description)\n",
    "    videos_upload_date.append(video_upload_date)\n",
    "    videos_duration.append(video_duration)\n",
    "    videos_views.append(video_views)\n",
    "    videos_likes.append(video_likes)\n",
    "    videos_comments.append(video_comments)\n",
    "    videos_tags.append(video_tags)\n",
    "    videos_thumbnail.append(video_thumbnail)\n",
    "    videos_favorite_count.append(video_favorite_count)\n",
    "    videos_region_restriction.append(video_region_restriction)\n",
    "    videos_captions.append(video_caption)\n",
    "\n",
    "# Calculate and print execution time\n",
    "end = time.time()\n",
    "print(f'This scraping operation took {round(end - start)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas DataFrame from the collected video data\n",
    "column_headers = ['id', 'yt_title', 'description', 'upload_date', 'duration', 'views', 'likes', 'comments_count', 'tags', 'thumbnail_url', 'favorite_count', 'region_restriction', 'captions_availability']\n",
    "lex_df0 = pd.DataFrame(list(zip(videos_id, videos_title, videos_description, videos_upload_date, videos_duration, videos_views, videos_likes, videos_comments, videos_tags, videos_thumbnail, videos_favorite_count, videos_region_restriction, videos_captions)), columns = column_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the videos transcripts using **youtube_transcript_api**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no transcript for video reYdQYZ9Rj4: no element found: line 1, column 0\n",
      "This youtube scraping operation took 96 seconds\n"
     ]
    }
   ],
   "source": [
    "# Record start time for performance measurement\n",
    "start = time.time()\n",
    "\n",
    "# Fetch and process transcripts (captions) for each video\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api._errors import TranscriptsDisabled, NoTranscriptFound\n",
    "\n",
    "# Create an new column to store video transcripts\n",
    "videos_captions_text = []\n",
    "\n",
    "# Loop through each video ID in the DataFrame to get its transcript\n",
    "for id in lex_df0['id']:\n",
    "    try:\n",
    "        # Check if captions are available for the current video\n",
    "        if lex_df0[lex_df0['id'] == id]['captions_availability'].values[0] == 'true':\n",
    "            try:\n",
    "                # Get the transcript for the video using the YouTube Transcript API\n",
    "                transcript = YouTubeTranscriptApi.get_transcript(id)\n",
    "                # Extract the text from each part of the transcript and join it into a single string\n",
    "                text = ' '.join([d['text'] for d in transcript])\n",
    "                # Append the combined transcript text to the list\n",
    "                videos_captions_text.append(text)\n",
    "            except (TranscriptsDisabled, NoTranscriptFound, Exception) as e:\n",
    "                # Handle exceptions if the transcript is disabled, not found, or any other error occurs\n",
    "                print(f\"no transcript for video {id}: {str(e)}\")\n",
    "                videos_captions_text.append(None)\n",
    "        else:\n",
    "            # Append None if captions are not available for the video\n",
    "            videos_captions_text.append(None)\n",
    "    except Exception as e:\n",
    "        # Handle any unexpected errors during transcript retrieval\n",
    "        print(f\"unexpected error for video {id}: {str(e)}\")\n",
    "        videos_captions_text.append(None)\n",
    "\n",
    "# Create a Pandas DataFrame from the collected video transcripts\n",
    "videos_captions_df = pd.DataFrame(videos_captions_text, columns=['captions_text'])\n",
    "\n",
    "# Calculate and print execution time\n",
    "end = time.time()\n",
    "print(f'This youtube scraping operation took {round(end - start)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>captions_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- Most people, most of the time, are polite, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>- The ideas that I am talking about are ideas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>- The big question for\\nme in that timeline is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- The following is a conversation\\nwith Jordan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- The following is a conversation with the fou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       captions_text\n",
       "0  - Most people, most of the time, are polite, c...\n",
       "1  - The ideas that I am talking about are ideas ...\n",
       "2  - The big question for\\nme in that timeline is...\n",
       "3  - The following is a conversation\\nwith Jordan...\n",
       "4  - The following is a conversation with the fou..."
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the output\n",
    "videos_captions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get top 5 said words of each video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store the top 5 words for each video\n",
    "top_5_words_in_video = []\n",
    "\n",
    "# Define a function to extract the top N most frequent words from a given text\n",
    "def get_top_n_words(text, n, exclude_list):\n",
    "    \"\"\"\n",
    "    Extracts the top N most frequent words from a transcript text, excluding words in a provided list.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text (video transcript).\n",
    "        n (int): The number of top words to return.\n",
    "        exclude_list (list): A list of words to exclude from the count.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains a word and its frequency, sorted by frequency in descending order.\n",
    "    \"\"\"\n",
    "    # Remove punctuation and convert text to lowercase\n",
    "    words = [word.lower().strip('.,?!:;()[]{}\\\"\\'') for word in text.split()]\n",
    "    # Filter out words present in the exclude list (case-insensitive)\n",
    "    words = [word for word in words if word.lower() not in [x.lower() for x in exclude_list]]\n",
    "    # Count word frequencies\n",
    "    c = Counter(words)\n",
    "    # Return the N most common words\n",
    "    return c.most_common(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This operation took 50 seconds\n"
     ]
    }
   ],
   "source": [
    "# Record start time for performance measurement\n",
    "start = time.time()\n",
    "\n",
    "# Create a list of the excluded words from the top five words\n",
    "exclude_list = [\"the\", \"a\", \"like\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\",\n",
    "                \"been\", \"before\", \"being\", \"one\", \"in\", \"not\", \"of\", \"is\", \"just\", \"even\", \"get\", \"to\", \"lot\", \"that\", \"his\", \"know\",\n",
    "                \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\",\n",
    "                \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"how\", \"how's\", \"i\",\n",
    "                \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"into\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\",\n",
    "                \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\",\n",
    "                \"so\", \"some\", \"such\", \"than\", \"that's\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\",\n",
    "                \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\",\n",
    "                \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\",\n",
    "                \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"uh\", \"don't\", \"um\", \"yeah\", \"actually\", \"also\",\n",
    "                \"going\", \"can\", \"something\", \"will\", \"no\", \"well\", \"many\", \"really\", \"things\", \"kind\", \"think\", \"say\", \"see\", \"basically\", \"man\"\n",
    "                \"right\", \"else\", \"isn't\", \"shall\", \"wasn't\", \"http\", \"however\", \"therefore\", \"can't\", \"through\", \"further\", \"shan't\", \"whom\", \"get\",\n",
    "                  \"is\", \"them\", \"but\", \"me\", \"too\", \"as\", \"once\", \"hadn't\", \"doing\", \"our\", \"which\", \"time\", \"good\", \"great\", \"little\", \"back\", \"stuff\", \"able\", \"life\", \"world\",\n",
    "                \"until\", \"nor\", \"we're\", \"they\", \"cannot\", \"any\", \"won't\", \"they'll\", \"why's\", \"because\", \"can't\", \"www\", \"people\", \"♪\", \"cus\", \"ago\"\n",
    "                \"haven't\", \"mustn't\", \"under\", \"against\", \"let's\", \"off\", \"shouldn't\", \"below\", \"has\", \"couldn't\", \"weren't\", \"human,\" \"idea,\" \"country\", \"system\", \n",
    "                \"while\", \"not\", \"was\", \"such\", \"ever\", \"yours\", \"it\", \"his\", \"myself\", \"you're\", \"than\", \"didn't\", \"obviously\", \"different\",\n",
    "                \"aren't\", \"does\", \"ought\", \"she's\", \"some\", \"by\", \"ours\", \"only\", \"should\", \"few\", \"since\", \"did\", \"theirs\", \"these\", \"were\", \"him\", \"on\", \"if\",\n",
    "                \"up\", \"where\", \"its\", \"wouldn't\", \"each\", \"with\", \"where's\", \"hasn't\", \"who\", \"for\", \"otherwise\", \"during\", \"those\", \"other\", \"before\", \"doesn't\", \"into\", \"herself\",\n",
    "                \"to\", \"how\", \"that's\", \"hence\", \"having\", \"own\", \"com\", \"why\", \"it's\", \"mean\", \"make\", \"want\", \"sort\", \"okay\", \"thing\", \"need\", \"go\", \"much\",\n",
    "                \"got\", \"way\", \"maybe\", \"upon\", \"100\", \"yes\", \"may\", \"look\", \"oh\", \"somebody\", \"around\", \"now\", \"said\", \"-\", \"lex\", \"might\", \"gonna\", \"guys\", \"cause\",\n",
    "                \"years\", \"thing\", \"things\", \"really\", \"very\", \"actually\", \"kind\", \"kinda\", \"sort\", \"sorta\", \"just\", \"mean\", \"think\", \"say\", \"said\", \"saying\", \"know\", \"going\", \"get\", \"got\", \"lot\", \"way\"]\n",
    "\n",
    "\n",
    "# Iterate through each transcript's text\n",
    "for text in videos_captions_text:\n",
    "  if text: # Check if the transcript exists (is not None)\n",
    "    # Get the top 5 most frequent words in the transcript, excluding the words in exclude_list\n",
    "    top_5_words = get_top_n_words(text, 5, exclude_list)\n",
    "    top_5_words_in_video.append(top_5_words)\n",
    "  else:\n",
    "     # If no transcript is available, append a message indicating that\n",
    "    top_5_words_in_video.append('no captions available')\n",
    "\n",
    "# Calculate and print execution time\n",
    "end = time.time()\n",
    "print(f'This operation took {round(end - start)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the top 5 words data and format it for the DataFrame\n",
    "top_five_words = []\n",
    "for item in top_5_words_in_video:\n",
    "    if isinstance(item, list):  # Check if the item is a list of (word, count) tuples\n",
    "        # Filter out any remaining excluded words that might have been missed in the previous step\n",
    "        filtered_words = [(word, count) for word, count in item\n",
    "                         if word.lower().strip('.,?!:;()[]{}\\\"\\'') not in exclude_list]\n",
    "\n",
    "        # Format the words and counts as a comma-separated string (\"word-count, word-count, ...\")\n",
    "        words_string = ', '.join([f\"{word}-{count}\" for word, count in filtered_words])\n",
    "        top_five_words.append([words_string])  # Append as a list to maintain structure\n",
    "    else:\n",
    "        # If no top words are available (e.g., 'no captions available'), append the existing value directly\n",
    "        top_five_words.append([item])  # Append the message or value from top_5_words_in_video\n",
    "\n",
    "\n",
    "# Create a DataFrame from the processed top 5 words data\n",
    "top_five_df = pd.DataFrame(top_five_words, columns=['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>yt_title</th>\n",
       "      <th>description</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>duration</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments_count</th>\n",
       "      <th>tags</th>\n",
       "      <th>thumbnail_url</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>region_restriction</th>\n",
       "      <th>captions_availability</th>\n",
       "      <th>top_five_words</th>\n",
       "      <th>captions_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abd5hguWKz0</td>\n",
       "      <td>Rick Spence: CIA, KGB, Illuminati, Secret Soci...</td>\n",
       "      <td>Rick Spence is a historian specializing in the...</td>\n",
       "      <td>2024-10-30T18:06:12Z</td>\n",
       "      <td>PT3H28M20S</td>\n",
       "      <td>901686</td>\n",
       "      <td>14696</td>\n",
       "      <td>2037</td>\n",
       "      <td>[Rick Spence, alex friedman, lex ai, lex debat...</td>\n",
       "      <td>https://i.ytimg.com/vi/abd5hguWKz0/hqdefault.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>true</td>\n",
       "      <td>jews-51, part-50, idea-49, german-49, intellig...</td>\n",
       "      <td>- Most people, most of the time, are polite, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MzkgWDCucNY</td>\n",
       "      <td>Bernie Sanders Interview | Lex Fridman Podcast...</td>\n",
       "      <td>Bernie Sanders is a US Senator from Vermont an...</td>\n",
       "      <td>2024-10-23T20:19:21Z</td>\n",
       "      <td>PT1H2M32S</td>\n",
       "      <td>1218968</td>\n",
       "      <td>23415</td>\n",
       "      <td>5665</td>\n",
       "      <td>[Bernie Sanders, alex friedman, lex ai, lex de...</td>\n",
       "      <td>https://i.ytimg.com/vi/MzkgWDCucNY/hqdefault.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>true</td>\n",
       "      <td>right-56, money-39, working-28, country-28, he...</td>\n",
       "      <td>- The ideas that I am talking about are ideas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NMHiLvirCb0</td>\n",
       "      <td>Graham Hancock: Lost Civilization of the Ice A...</td>\n",
       "      <td>Graham Hancock a journalist and author who for...</td>\n",
       "      <td>2024-10-16T12:16:21Z</td>\n",
       "      <td>PT2H33M2S</td>\n",
       "      <td>2656311</td>\n",
       "      <td>43799</td>\n",
       "      <td>7821</td>\n",
       "      <td>[Graham Hancock, alex friedman, lex ai, lex de...</td>\n",
       "      <td>https://i.ytimg.com/vi/NMHiLvirCb0/hqdefault.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>true</td>\n",
       "      <td>ago-63, civilization-60, human-53, ancient-48,...</td>\n",
       "      <td>- The big question for\\nme in that timeline is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q8VePUwjB9Y</td>\n",
       "      <td>Jordan Peterson: Nietzsche, Hitler, God, Psych...</td>\n",
       "      <td>Jordan Peterson is a psychologist, author, lec...</td>\n",
       "      <td>2024-10-11T18:03:40Z</td>\n",
       "      <td>PT2H23M5S</td>\n",
       "      <td>1132848</td>\n",
       "      <td>25316</td>\n",
       "      <td>4191</td>\n",
       "      <td>[Jordan Peterson, alex friedman, lex ai, lex d...</td>\n",
       "      <td>https://i.ytimg.com/vi/q8VePUwjB9Y/hqdefault.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>true</td>\n",
       "      <td>right-84, god-40, ideas-37, idea-36, nietzsche-33</td>\n",
       "      <td>- The following is a conversation\\nwith Jordan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oFfVt3S51T4</td>\n",
       "      <td>Cursor Team: Future of Programming with AI | L...</td>\n",
       "      <td>Aman Sanger, Arvid Lunnemark, Michael Truell, ...</td>\n",
       "      <td>2024-10-06T18:43:14Z</td>\n",
       "      <td>PT2H29M5S</td>\n",
       "      <td>488086</td>\n",
       "      <td>9397</td>\n",
       "      <td>881</td>\n",
       "      <td>[Cursor Team, alex friedman, lex ai, lex debat...</td>\n",
       "      <td>https://i.ytimg.com/vi/oFfVt3S51T4/hqdefault.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>true</td>\n",
       "      <td>code-194, model-156, models-110, programming-5...</td>\n",
       "      <td>- The following is a conversation with the fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AzzE7GOvYz8</td>\n",
       "      <td>Ed Barnhart: Maya, Aztec, Inca, and Lost Civil...</td>\n",
       "      <td>Ed Barnhart is an archaeologist and explorer s...</td>\n",
       "      <td>2024-09-30T17:23:24Z</td>\n",
       "      <td>PT3H28M51S</td>\n",
       "      <td>2750975</td>\n",
       "      <td>25303</td>\n",
       "      <td>2801</td>\n",
       "      <td>[Ed Barnhart, alex friedman, lex ai, lex debat...</td>\n",
       "      <td>https://i.ytimg.com/vi/AzzE7GOvYz8/hqdefault.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>true</td>\n",
       "      <td>maya-88, right-63, america-54, big-54, civiliz...</td>\n",
       "      <td>- For the vast majority\\nof human existence. W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Q8Qk_3a3lUw</td>\n",
       "      <td>Vivek Ramaswamy: Trump, Conservatism, National...</td>\n",
       "      <td>Vivek Ramaswamy is a conservative politician, ...</td>\n",
       "      <td>2024-09-25T17:59:15Z</td>\n",
       "      <td>PT2H40M26S</td>\n",
       "      <td>770550</td>\n",
       "      <td>20913</td>\n",
       "      <td>6031</td>\n",
       "      <td>[Vivek Ramaswamy, alex friedman, lex ai, lex d...</td>\n",
       "      <td>https://i.ytimg.com/vi/Q8Qk_3a3lUw/hqdefault.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>true</td>\n",
       "      <td>right-125, states-118, united-111, country-94,...</td>\n",
       "      <td>- The way I would do it, 75% headcount reducti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>s1oTH4Sjvzg</td>\n",
       "      <td>Vejas Liulevicius: Communism, Marxism, Nazism,...</td>\n",
       "      <td>Vejas Liulevicius is a historian specializing ...</td>\n",
       "      <td>2024-09-20T20:30:55Z</td>\n",
       "      <td>PT3H31M58S</td>\n",
       "      <td>909253</td>\n",
       "      <td>10610</td>\n",
       "      <td>1638</td>\n",
       "      <td>[Vejas Liulevicius, alex friedman, lex ai, lex...</td>\n",
       "      <td>https://i.ytimg.com/vi/s1oTH4Sjvzg/hqdefault.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>true</td>\n",
       "      <td>marx-87, history-80, war-68, soviet-64, right-60</td>\n",
       "      <td>- And the outcome here is\\na horrific, manmade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DyoVVSggPjY</td>\n",
       "      <td>Gregory Aldrete: The Roman Empire - Rise and F...</td>\n",
       "      <td>Gregory Aldrete is a historian specializing in...</td>\n",
       "      <td>2024-09-12T19:05:50Z</td>\n",
       "      <td>PT3H42M21S</td>\n",
       "      <td>3755496</td>\n",
       "      <td>43979</td>\n",
       "      <td>3773</td>\n",
       "      <td>[Gregory Aldrete, alex friedman, lex ai, lex d...</td>\n",
       "      <td>https://i.ytimg.com/vi/DyoVVSggPjY/hqdefault.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>true</td>\n",
       "      <td>roman-257, romans-150, rome-112, empire-110, h...</td>\n",
       "      <td>- So Rome always wins because even if they los...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>qCbfTN-caFI</td>\n",
       "      <td>Donald Trump Interview | Lex Fridman Podcast #442</td>\n",
       "      <td>Donald Trump is the 45th President of the Unit...</td>\n",
       "      <td>2024-09-03T16:21:05Z</td>\n",
       "      <td>PT1H4M18S</td>\n",
       "      <td>6268026</td>\n",
       "      <td>227993</td>\n",
       "      <td>59812</td>\n",
       "      <td>[Donald Trump, alex friedman, lex ai, lex deba...</td>\n",
       "      <td>https://i.ytimg.com/vi/qCbfTN-caFI/hqdefault.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>true</td>\n",
       "      <td>right-33, country-31, done-22, big-18, electio...</td>\n",
       "      <td>- I don't know if you know this, but some peop...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                           yt_title  \\\n",
       "0  abd5hguWKz0  Rick Spence: CIA, KGB, Illuminati, Secret Soci...   \n",
       "1  MzkgWDCucNY  Bernie Sanders Interview | Lex Fridman Podcast...   \n",
       "2  NMHiLvirCb0  Graham Hancock: Lost Civilization of the Ice A...   \n",
       "3  q8VePUwjB9Y  Jordan Peterson: Nietzsche, Hitler, God, Psych...   \n",
       "4  oFfVt3S51T4  Cursor Team: Future of Programming with AI | L...   \n",
       "5  AzzE7GOvYz8  Ed Barnhart: Maya, Aztec, Inca, and Lost Civil...   \n",
       "6  Q8Qk_3a3lUw  Vivek Ramaswamy: Trump, Conservatism, National...   \n",
       "7  s1oTH4Sjvzg  Vejas Liulevicius: Communism, Marxism, Nazism,...   \n",
       "8  DyoVVSggPjY  Gregory Aldrete: The Roman Empire - Rise and F...   \n",
       "9  qCbfTN-caFI  Donald Trump Interview | Lex Fridman Podcast #442   \n",
       "\n",
       "                                         description           upload_date  \\\n",
       "0  Rick Spence is a historian specializing in the...  2024-10-30T18:06:12Z   \n",
       "1  Bernie Sanders is a US Senator from Vermont an...  2024-10-23T20:19:21Z   \n",
       "2  Graham Hancock a journalist and author who for...  2024-10-16T12:16:21Z   \n",
       "3  Jordan Peterson is a psychologist, author, lec...  2024-10-11T18:03:40Z   \n",
       "4  Aman Sanger, Arvid Lunnemark, Michael Truell, ...  2024-10-06T18:43:14Z   \n",
       "5  Ed Barnhart is an archaeologist and explorer s...  2024-09-30T17:23:24Z   \n",
       "6  Vivek Ramaswamy is a conservative politician, ...  2024-09-25T17:59:15Z   \n",
       "7  Vejas Liulevicius is a historian specializing ...  2024-09-20T20:30:55Z   \n",
       "8  Gregory Aldrete is a historian specializing in...  2024-09-12T19:05:50Z   \n",
       "9  Donald Trump is the 45th President of the Unit...  2024-09-03T16:21:05Z   \n",
       "\n",
       "     duration    views   likes comments_count  \\\n",
       "0  PT3H28M20S   901686   14696           2037   \n",
       "1   PT1H2M32S  1218968   23415           5665   \n",
       "2   PT2H33M2S  2656311   43799           7821   \n",
       "3   PT2H23M5S  1132848   25316           4191   \n",
       "4   PT2H29M5S   488086    9397            881   \n",
       "5  PT3H28M51S  2750975   25303           2801   \n",
       "6  PT2H40M26S   770550   20913           6031   \n",
       "7  PT3H31M58S   909253   10610           1638   \n",
       "8  PT3H42M21S  3755496   43979           3773   \n",
       "9   PT1H4M18S  6268026  227993          59812   \n",
       "\n",
       "                                                tags  \\\n",
       "0  [Rick Spence, alex friedman, lex ai, lex debat...   \n",
       "1  [Bernie Sanders, alex friedman, lex ai, lex de...   \n",
       "2  [Graham Hancock, alex friedman, lex ai, lex de...   \n",
       "3  [Jordan Peterson, alex friedman, lex ai, lex d...   \n",
       "4  [Cursor Team, alex friedman, lex ai, lex debat...   \n",
       "5  [Ed Barnhart, alex friedman, lex ai, lex debat...   \n",
       "6  [Vivek Ramaswamy, alex friedman, lex ai, lex d...   \n",
       "7  [Vejas Liulevicius, alex friedman, lex ai, lex...   \n",
       "8  [Gregory Aldrete, alex friedman, lex ai, lex d...   \n",
       "9  [Donald Trump, alex friedman, lex ai, lex deba...   \n",
       "\n",
       "                                      thumbnail_url favorite_count  \\\n",
       "0  https://i.ytimg.com/vi/abd5hguWKz0/hqdefault.jpg              0   \n",
       "1  https://i.ytimg.com/vi/MzkgWDCucNY/hqdefault.jpg              0   \n",
       "2  https://i.ytimg.com/vi/NMHiLvirCb0/hqdefault.jpg              0   \n",
       "3  https://i.ytimg.com/vi/q8VePUwjB9Y/hqdefault.jpg              0   \n",
       "4  https://i.ytimg.com/vi/oFfVt3S51T4/hqdefault.jpg              0   \n",
       "5  https://i.ytimg.com/vi/AzzE7GOvYz8/hqdefault.jpg              0   \n",
       "6  https://i.ytimg.com/vi/Q8Qk_3a3lUw/hqdefault.jpg              0   \n",
       "7  https://i.ytimg.com/vi/s1oTH4Sjvzg/hqdefault.jpg              0   \n",
       "8  https://i.ytimg.com/vi/DyoVVSggPjY/hqdefault.jpg              0   \n",
       "9  https://i.ytimg.com/vi/qCbfTN-caFI/hqdefault.jpg              0   \n",
       "\n",
       "  region_restriction captions_availability  \\\n",
       "0               None                  true   \n",
       "1               None                  true   \n",
       "2               None                  true   \n",
       "3               None                  true   \n",
       "4               None                  true   \n",
       "5               None                  true   \n",
       "6               None                  true   \n",
       "7               None                  true   \n",
       "8               None                  true   \n",
       "9               None                  true   \n",
       "\n",
       "                                      top_five_words  \\\n",
       "0  jews-51, part-50, idea-49, german-49, intellig...   \n",
       "1  right-56, money-39, working-28, country-28, he...   \n",
       "2  ago-63, civilization-60, human-53, ancient-48,...   \n",
       "3  right-84, god-40, ideas-37, idea-36, nietzsche-33   \n",
       "4  code-194, model-156, models-110, programming-5...   \n",
       "5  maya-88, right-63, america-54, big-54, civiliz...   \n",
       "6  right-125, states-118, united-111, country-94,...   \n",
       "7   marx-87, history-80, war-68, soviet-64, right-60   \n",
       "8  roman-257, romans-150, rome-112, empire-110, h...   \n",
       "9  right-33, country-31, done-22, big-18, electio...   \n",
       "\n",
       "                                       captions_text  \n",
       "0  - Most people, most of the time, are polite, c...  \n",
       "1  - The ideas that I am talking about are ideas ...  \n",
       "2  - The big question for\\nme in that timeline is...  \n",
       "3  - The following is a conversation\\nwith Jordan...  \n",
       "4  - The following is a conversation with the fou...  \n",
       "5  - For the vast majority\\nof human existence. W...  \n",
       "6  - The way I would do it, 75% headcount reducti...  \n",
       "7  - And the outcome here is\\na horrific, manmade...  \n",
       "8  - So Rome always wins because even if they los...  \n",
       "9  - I don't know if you know this, but some peop...  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the 'top_five_words' and 'captions_text' columns to the main DataFrame\n",
    "lex_df0['top_five_words'] = top_five_df['words']\n",
    "lex_df0['captions_text'] = videos_captions_df['captions_text']\n",
    "\n",
    "# Display the first 10 rows of the updated DataFrame\n",
    "lex_df0.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get videos' URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the video Ids to YouTube URLs\n",
    "lex_df0['yt_url'] = 'https://www.youtube.com/watch?v=' + lex_df0['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Epsidoe Number, Guest Name, and Episode Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>yt_title</th>\n",
       "      <th>description</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>duration</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments_count</th>\n",
       "      <th>tags</th>\n",
       "      <th>thumbnail_url</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>region_restriction</th>\n",
       "      <th>captions_availability</th>\n",
       "      <th>top_five_words</th>\n",
       "      <th>captions_text</th>\n",
       "      <th>yt_url</th>\n",
       "      <th>number</th>\n",
       "      <th>guest</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abd5hguWKz0</td>\n",
       "      <td>Rick Spence: CIA, KGB, Illuminati, Secret Soci...</td>\n",
       "      <td>Rick Spence is a historian specializing in the...</td>\n",
       "      <td>2024-10-30T18:06:12Z</td>\n",
       "      <td>PT3H28M20S</td>\n",
       "      <td>901686</td>\n",
       "      <td>14696</td>\n",
       "      <td>2037</td>\n",
       "      <td>[Rick Spence, alex friedman, lex ai, lex debat...</td>\n",
       "      <td>https://i.ytimg.com/vi/abd5hguWKz0/hqdefault.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>true</td>\n",
       "      <td>jews-51, part-50, idea-49, german-49, intellig...</td>\n",
       "      <td>- Most people, most of the time, are polite, c...</td>\n",
       "      <td>https://www.youtube.com/watch?v=abd5hguWKz0</td>\n",
       "      <td>451</td>\n",
       "      <td>Rick Spence</td>\n",
       "      <td>CIA, KGB, Illuminati, Secret Societies, Cults ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MzkgWDCucNY</td>\n",
       "      <td>Bernie Sanders Interview | Lex Fridman Podcast...</td>\n",
       "      <td>Bernie Sanders is a US Senator from Vermont an...</td>\n",
       "      <td>2024-10-23T20:19:21Z</td>\n",
       "      <td>PT1H2M32S</td>\n",
       "      <td>1218968</td>\n",
       "      <td>23415</td>\n",
       "      <td>5665</td>\n",
       "      <td>[Bernie Sanders, alex friedman, lex ai, lex de...</td>\n",
       "      <td>https://i.ytimg.com/vi/MzkgWDCucNY/hqdefault.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>true</td>\n",
       "      <td>right-56, money-39, working-28, country-28, he...</td>\n",
       "      <td>- The ideas that I am talking about are ideas ...</td>\n",
       "      <td>https://www.youtube.com/watch?v=MzkgWDCucNY</td>\n",
       "      <td>450</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NMHiLvirCb0</td>\n",
       "      <td>Graham Hancock: Lost Civilization of the Ice A...</td>\n",
       "      <td>Graham Hancock a journalist and author who for...</td>\n",
       "      <td>2024-10-16T12:16:21Z</td>\n",
       "      <td>PT2H33M2S</td>\n",
       "      <td>2656311</td>\n",
       "      <td>43799</td>\n",
       "      <td>7821</td>\n",
       "      <td>[Graham Hancock, alex friedman, lex ai, lex de...</td>\n",
       "      <td>https://i.ytimg.com/vi/NMHiLvirCb0/hqdefault.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>true</td>\n",
       "      <td>ago-63, civilization-60, human-53, ancient-48,...</td>\n",
       "      <td>- The big question for\\nme in that timeline is...</td>\n",
       "      <td>https://www.youtube.com/watch?v=NMHiLvirCb0</td>\n",
       "      <td>449</td>\n",
       "      <td>Graham Hancock</td>\n",
       "      <td>Lost Civilization of the Ice Age &amp; Ancient Hum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q8VePUwjB9Y</td>\n",
       "      <td>Jordan Peterson: Nietzsche, Hitler, God, Psych...</td>\n",
       "      <td>Jordan Peterson is a psychologist, author, lec...</td>\n",
       "      <td>2024-10-11T18:03:40Z</td>\n",
       "      <td>PT2H23M5S</td>\n",
       "      <td>1132848</td>\n",
       "      <td>25316</td>\n",
       "      <td>4191</td>\n",
       "      <td>[Jordan Peterson, alex friedman, lex ai, lex d...</td>\n",
       "      <td>https://i.ytimg.com/vi/q8VePUwjB9Y/hqdefault.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>true</td>\n",
       "      <td>right-84, god-40, ideas-37, idea-36, nietzsche-33</td>\n",
       "      <td>- The following is a conversation\\nwith Jordan...</td>\n",
       "      <td>https://www.youtube.com/watch?v=q8VePUwjB9Y</td>\n",
       "      <td>448</td>\n",
       "      <td>Jordan Peterson</td>\n",
       "      <td>Nietzsche, Hitler, God, Psychopathy, Suffering...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oFfVt3S51T4</td>\n",
       "      <td>Cursor Team: Future of Programming with AI | L...</td>\n",
       "      <td>Aman Sanger, Arvid Lunnemark, Michael Truell, ...</td>\n",
       "      <td>2024-10-06T18:43:14Z</td>\n",
       "      <td>PT2H29M5S</td>\n",
       "      <td>488086</td>\n",
       "      <td>9397</td>\n",
       "      <td>881</td>\n",
       "      <td>[Cursor Team, alex friedman, lex ai, lex debat...</td>\n",
       "      <td>https://i.ytimg.com/vi/oFfVt3S51T4/hqdefault.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>true</td>\n",
       "      <td>code-194, model-156, models-110, programming-5...</td>\n",
       "      <td>- The following is a conversation with the fou...</td>\n",
       "      <td>https://www.youtube.com/watch?v=oFfVt3S51T4</td>\n",
       "      <td>447</td>\n",
       "      <td>Cursor Team</td>\n",
       "      <td>Future of Programming with AI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                           yt_title  \\\n",
       "0  abd5hguWKz0  Rick Spence: CIA, KGB, Illuminati, Secret Soci...   \n",
       "1  MzkgWDCucNY  Bernie Sanders Interview | Lex Fridman Podcast...   \n",
       "2  NMHiLvirCb0  Graham Hancock: Lost Civilization of the Ice A...   \n",
       "3  q8VePUwjB9Y  Jordan Peterson: Nietzsche, Hitler, God, Psych...   \n",
       "4  oFfVt3S51T4  Cursor Team: Future of Programming with AI | L...   \n",
       "\n",
       "                                         description           upload_date  \\\n",
       "0  Rick Spence is a historian specializing in the...  2024-10-30T18:06:12Z   \n",
       "1  Bernie Sanders is a US Senator from Vermont an...  2024-10-23T20:19:21Z   \n",
       "2  Graham Hancock a journalist and author who for...  2024-10-16T12:16:21Z   \n",
       "3  Jordan Peterson is a psychologist, author, lec...  2024-10-11T18:03:40Z   \n",
       "4  Aman Sanger, Arvid Lunnemark, Michael Truell, ...  2024-10-06T18:43:14Z   \n",
       "\n",
       "     duration    views  likes comments_count  \\\n",
       "0  PT3H28M20S   901686  14696           2037   \n",
       "1   PT1H2M32S  1218968  23415           5665   \n",
       "2   PT2H33M2S  2656311  43799           7821   \n",
       "3   PT2H23M5S  1132848  25316           4191   \n",
       "4   PT2H29M5S   488086   9397            881   \n",
       "\n",
       "                                                tags  \\\n",
       "0  [Rick Spence, alex friedman, lex ai, lex debat...   \n",
       "1  [Bernie Sanders, alex friedman, lex ai, lex de...   \n",
       "2  [Graham Hancock, alex friedman, lex ai, lex de...   \n",
       "3  [Jordan Peterson, alex friedman, lex ai, lex d...   \n",
       "4  [Cursor Team, alex friedman, lex ai, lex debat...   \n",
       "\n",
       "                                      thumbnail_url favorite_count  \\\n",
       "0  https://i.ytimg.com/vi/abd5hguWKz0/hqdefault.jpg              0   \n",
       "1  https://i.ytimg.com/vi/MzkgWDCucNY/hqdefault.jpg              0   \n",
       "2  https://i.ytimg.com/vi/NMHiLvirCb0/hqdefault.jpg              0   \n",
       "3  https://i.ytimg.com/vi/q8VePUwjB9Y/hqdefault.jpg              0   \n",
       "4  https://i.ytimg.com/vi/oFfVt3S51T4/hqdefault.jpg              0   \n",
       "\n",
       "  region_restriction captions_availability  \\\n",
       "0               None                  true   \n",
       "1               None                  true   \n",
       "2               None                  true   \n",
       "3               None                  true   \n",
       "4               None                  true   \n",
       "\n",
       "                                      top_five_words  \\\n",
       "0  jews-51, part-50, idea-49, german-49, intellig...   \n",
       "1  right-56, money-39, working-28, country-28, he...   \n",
       "2  ago-63, civilization-60, human-53, ancient-48,...   \n",
       "3  right-84, god-40, ideas-37, idea-36, nietzsche-33   \n",
       "4  code-194, model-156, models-110, programming-5...   \n",
       "\n",
       "                                       captions_text  \\\n",
       "0  - Most people, most of the time, are polite, c...   \n",
       "1  - The ideas that I am talking about are ideas ...   \n",
       "2  - The big question for\\nme in that timeline is...   \n",
       "3  - The following is a conversation\\nwith Jordan...   \n",
       "4  - The following is a conversation with the fou...   \n",
       "\n",
       "                                        yt_url  number            guest  \\\n",
       "0  https://www.youtube.com/watch?v=abd5hguWKz0     451      Rick Spence   \n",
       "1  https://www.youtube.com/watch?v=MzkgWDCucNY     450   Bernie Sanders   \n",
       "2  https://www.youtube.com/watch?v=NMHiLvirCb0     449   Graham Hancock   \n",
       "3  https://www.youtube.com/watch?v=q8VePUwjB9Y     448  Jordan Peterson   \n",
       "4  https://www.youtube.com/watch?v=oFfVt3S51T4     447      Cursor Team   \n",
       "\n",
       "                                             summary  \n",
       "0  CIA, KGB, Illuminati, Secret Societies, Cults ...  \n",
       "1                                               None  \n",
       "2  Lost Civilization of the Ice Age & Ancient Hum...  \n",
       "3  Nietzsche, Hitler, God, Psychopathy, Suffering...  \n",
       "4                      Future of Programming with AI  "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract episode numbers\n",
    "lex_df0['number'] = lex_df0[lex_df0['yt_title'].str.contains('#', na=False)]['yt_title'].str.split(\"#\").str[1]\n",
    "lex_df0['number'] = lex_df0['number'].fillna('').astype(int)\n",
    "\n",
    "# First split on '|' and keep only the first part\n",
    "lex_df0['clean_title'] = lex_df0['yt_title'].str.split('|').str[0]\n",
    "\n",
    "# Then split that into Guest and Summary on ':'\n",
    "lex_df0[['guest', 'summary']] = lex_df0['clean_title'].str.split(\":\", n=1, expand=True)\n",
    "\n",
    "# Keep only first two words of Guest name\n",
    "lex_df0['guest'] = lex_df0['guest'].str.split().str[:2].str.join(' ')\n",
    "\n",
    "# Drop intermediate column\n",
    "lex_df0.drop(columns='clean_title', inplace=True)\n",
    "\n",
    "# Clean up any remaining whitespace\n",
    "lex_df0['guest'] = lex_df0['guest'].str.strip()\n",
    "lex_df0['summary'] = lex_df0['summary'].str.strip()\n",
    "\n",
    "# Display the first rows of the updated DataFrame\n",
    "lex_df0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>yt_title</th>\n",
       "      <th>description</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>duration</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments_count</th>\n",
       "      <th>tags</th>\n",
       "      <th>thumbnail_url</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>region_restriction</th>\n",
       "      <th>captions_availability</th>\n",
       "      <th>top_five_words</th>\n",
       "      <th>captions_text</th>\n",
       "      <th>yt_url</th>\n",
       "      <th>number</th>\n",
       "      <th>guest</th>\n",
       "      <th>summary</th>\n",
       "      <th>duration_minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abd5hguWKz0</td>\n",
       "      <td>Rick Spence: CIA, KGB, Illuminati, Secret Soci...</td>\n",
       "      <td>Rick Spence is a historian specializing in the...</td>\n",
       "      <td>2024-10-30T18:06:12Z</td>\n",
       "      <td>0 days 03:28:20</td>\n",
       "      <td>901686</td>\n",
       "      <td>14696</td>\n",
       "      <td>2037</td>\n",
       "      <td>[Rick Spence, alex friedman, lex ai, lex debat...</td>\n",
       "      <td>https://i.ytimg.com/vi/abd5hguWKz0/hqdefault.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>true</td>\n",
       "      <td>jews-51, part-50, idea-49, german-49, intellig...</td>\n",
       "      <td>- Most people, most of the time, are polite, c...</td>\n",
       "      <td>https://www.youtube.com/watch?v=abd5hguWKz0</td>\n",
       "      <td>451</td>\n",
       "      <td>Rick Spence</td>\n",
       "      <td>CIA, KGB, Illuminati, Secret Societies, Cults ...</td>\n",
       "      <td>208.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MzkgWDCucNY</td>\n",
       "      <td>Bernie Sanders Interview | Lex Fridman Podcast...</td>\n",
       "      <td>Bernie Sanders is a US Senator from Vermont an...</td>\n",
       "      <td>2024-10-23T20:19:21Z</td>\n",
       "      <td>0 days 01:02:32</td>\n",
       "      <td>1218968</td>\n",
       "      <td>23415</td>\n",
       "      <td>5665</td>\n",
       "      <td>[Bernie Sanders, alex friedman, lex ai, lex de...</td>\n",
       "      <td>https://i.ytimg.com/vi/MzkgWDCucNY/hqdefault.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>true</td>\n",
       "      <td>right-56, money-39, working-28, country-28, he...</td>\n",
       "      <td>- The ideas that I am talking about are ideas ...</td>\n",
       "      <td>https://www.youtube.com/watch?v=MzkgWDCucNY</td>\n",
       "      <td>450</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>None</td>\n",
       "      <td>62.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NMHiLvirCb0</td>\n",
       "      <td>Graham Hancock: Lost Civilization of the Ice A...</td>\n",
       "      <td>Graham Hancock a journalist and author who for...</td>\n",
       "      <td>2024-10-16T12:16:21Z</td>\n",
       "      <td>0 days 02:33:02</td>\n",
       "      <td>2656311</td>\n",
       "      <td>43799</td>\n",
       "      <td>7821</td>\n",
       "      <td>[Graham Hancock, alex friedman, lex ai, lex de...</td>\n",
       "      <td>https://i.ytimg.com/vi/NMHiLvirCb0/hqdefault.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>true</td>\n",
       "      <td>ago-63, civilization-60, human-53, ancient-48,...</td>\n",
       "      <td>- The big question for\\nme in that timeline is...</td>\n",
       "      <td>https://www.youtube.com/watch?v=NMHiLvirCb0</td>\n",
       "      <td>449</td>\n",
       "      <td>Graham Hancock</td>\n",
       "      <td>Lost Civilization of the Ice Age &amp; Ancient Hum...</td>\n",
       "      <td>153.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q8VePUwjB9Y</td>\n",
       "      <td>Jordan Peterson: Nietzsche, Hitler, God, Psych...</td>\n",
       "      <td>Jordan Peterson is a psychologist, author, lec...</td>\n",
       "      <td>2024-10-11T18:03:40Z</td>\n",
       "      <td>0 days 02:23:05</td>\n",
       "      <td>1132848</td>\n",
       "      <td>25316</td>\n",
       "      <td>4191</td>\n",
       "      <td>[Jordan Peterson, alex friedman, lex ai, lex d...</td>\n",
       "      <td>https://i.ytimg.com/vi/q8VePUwjB9Y/hqdefault.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>true</td>\n",
       "      <td>right-84, god-40, ideas-37, idea-36, nietzsche-33</td>\n",
       "      <td>- The following is a conversation\\nwith Jordan...</td>\n",
       "      <td>https://www.youtube.com/watch?v=q8VePUwjB9Y</td>\n",
       "      <td>448</td>\n",
       "      <td>Jordan Peterson</td>\n",
       "      <td>Nietzsche, Hitler, God, Psychopathy, Suffering...</td>\n",
       "      <td>143.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oFfVt3S51T4</td>\n",
       "      <td>Cursor Team: Future of Programming with AI | L...</td>\n",
       "      <td>Aman Sanger, Arvid Lunnemark, Michael Truell, ...</td>\n",
       "      <td>2024-10-06T18:43:14Z</td>\n",
       "      <td>0 days 02:29:05</td>\n",
       "      <td>488086</td>\n",
       "      <td>9397</td>\n",
       "      <td>881</td>\n",
       "      <td>[Cursor Team, alex friedman, lex ai, lex debat...</td>\n",
       "      <td>https://i.ytimg.com/vi/oFfVt3S51T4/hqdefault.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>true</td>\n",
       "      <td>code-194, model-156, models-110, programming-5...</td>\n",
       "      <td>- The following is a conversation with the fou...</td>\n",
       "      <td>https://www.youtube.com/watch?v=oFfVt3S51T4</td>\n",
       "      <td>447</td>\n",
       "      <td>Cursor Team</td>\n",
       "      <td>Future of Programming with AI</td>\n",
       "      <td>149.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                           yt_title  \\\n",
       "0  abd5hguWKz0  Rick Spence: CIA, KGB, Illuminati, Secret Soci...   \n",
       "1  MzkgWDCucNY  Bernie Sanders Interview | Lex Fridman Podcast...   \n",
       "2  NMHiLvirCb0  Graham Hancock: Lost Civilization of the Ice A...   \n",
       "3  q8VePUwjB9Y  Jordan Peterson: Nietzsche, Hitler, God, Psych...   \n",
       "4  oFfVt3S51T4  Cursor Team: Future of Programming with AI | L...   \n",
       "\n",
       "                                         description           upload_date  \\\n",
       "0  Rick Spence is a historian specializing in the...  2024-10-30T18:06:12Z   \n",
       "1  Bernie Sanders is a US Senator from Vermont an...  2024-10-23T20:19:21Z   \n",
       "2  Graham Hancock a journalist and author who for...  2024-10-16T12:16:21Z   \n",
       "3  Jordan Peterson is a psychologist, author, lec...  2024-10-11T18:03:40Z   \n",
       "4  Aman Sanger, Arvid Lunnemark, Michael Truell, ...  2024-10-06T18:43:14Z   \n",
       "\n",
       "         duration    views  likes comments_count  \\\n",
       "0 0 days 03:28:20   901686  14696           2037   \n",
       "1 0 days 01:02:32  1218968  23415           5665   \n",
       "2 0 days 02:33:02  2656311  43799           7821   \n",
       "3 0 days 02:23:05  1132848  25316           4191   \n",
       "4 0 days 02:29:05   488086   9397            881   \n",
       "\n",
       "                                                tags  \\\n",
       "0  [Rick Spence, alex friedman, lex ai, lex debat...   \n",
       "1  [Bernie Sanders, alex friedman, lex ai, lex de...   \n",
       "2  [Graham Hancock, alex friedman, lex ai, lex de...   \n",
       "3  [Jordan Peterson, alex friedman, lex ai, lex d...   \n",
       "4  [Cursor Team, alex friedman, lex ai, lex debat...   \n",
       "\n",
       "                                      thumbnail_url favorite_count  \\\n",
       "0  https://i.ytimg.com/vi/abd5hguWKz0/hqdefault.jpg              0   \n",
       "1  https://i.ytimg.com/vi/MzkgWDCucNY/hqdefault.jpg              0   \n",
       "2  https://i.ytimg.com/vi/NMHiLvirCb0/hqdefault.jpg              0   \n",
       "3  https://i.ytimg.com/vi/q8VePUwjB9Y/hqdefault.jpg              0   \n",
       "4  https://i.ytimg.com/vi/oFfVt3S51T4/hqdefault.jpg              0   \n",
       "\n",
       "  region_restriction captions_availability  \\\n",
       "0               None                  true   \n",
       "1               None                  true   \n",
       "2               None                  true   \n",
       "3               None                  true   \n",
       "4               None                  true   \n",
       "\n",
       "                                      top_five_words  \\\n",
       "0  jews-51, part-50, idea-49, german-49, intellig...   \n",
       "1  right-56, money-39, working-28, country-28, he...   \n",
       "2  ago-63, civilization-60, human-53, ancient-48,...   \n",
       "3  right-84, god-40, ideas-37, idea-36, nietzsche-33   \n",
       "4  code-194, model-156, models-110, programming-5...   \n",
       "\n",
       "                                       captions_text  \\\n",
       "0  - Most people, most of the time, are polite, c...   \n",
       "1  - The ideas that I am talking about are ideas ...   \n",
       "2  - The big question for\\nme in that timeline is...   \n",
       "3  - The following is a conversation\\nwith Jordan...   \n",
       "4  - The following is a conversation with the fou...   \n",
       "\n",
       "                                        yt_url  number            guest  \\\n",
       "0  https://www.youtube.com/watch?v=abd5hguWKz0     451      Rick Spence   \n",
       "1  https://www.youtube.com/watch?v=MzkgWDCucNY     450   Bernie Sanders   \n",
       "2  https://www.youtube.com/watch?v=NMHiLvirCb0     449   Graham Hancock   \n",
       "3  https://www.youtube.com/watch?v=q8VePUwjB9Y     448  Jordan Peterson   \n",
       "4  https://www.youtube.com/watch?v=oFfVt3S51T4     447      Cursor Team   \n",
       "\n",
       "                                             summary  duration_minutes  \n",
       "0  CIA, KGB, Illuminati, Secret Societies, Cults ...        208.333333  \n",
       "1                                               None         62.533333  \n",
       "2  Lost Civilization of the Ice Age & Ancient Hum...        153.033333  \n",
       "3  Nietzsche, Hitler, God, Psychopathy, Suffering...        143.083333  \n",
       "4                      Future of Programming with AI        149.083333  "
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the 'duration' column from ISO 8601 format to a timedelta object\n",
    "def convert_duration(duration):\n",
    "    \"\"\"\n",
    "    Converts an ISO 8601 duration string (e.g., \"PT1H23M45S\") to a timedelta object.\n",
    "\n",
    "    Args:\n",
    "        duration (str): The ISO 8601 duration string.\n",
    "\n",
    "    Returns:\n",
    "        timedelta: The equivalent timedelta object.\n",
    "    \"\"\"\n",
    "    duration = duration[2:] # Remove the \"PT\" prefix\n",
    "\n",
    "    hours = 0\n",
    "    minutes = 0\n",
    "    seconds = 0\n",
    "\n",
    "    if \"H\" in duration:\n",
    "        hours, duration = int(duration.split(\"H\")[0]), duration.split(\"H\")[1] #Extract Hour\n",
    "    if \"M\" in duration:\n",
    "        minutes, duration = int(duration.split(\"M\")[0]) if duration.split(\"M\")[0] else 0 , duration.split(\"M\")[1] if len(duration.split(\"M\")) > 1 else \"\" #Extract minutes\n",
    "    if \"S\" in duration:\n",
    "        seconds = int(duration.split(\"S\")[0]) if duration.split(\"S\")[0] else 0 #Extract seconds\n",
    "\n",
    "    total_seconds = 3600 * hours + 60 * minutes + seconds # Calculate total seconds\n",
    "\n",
    "    duration = datetime.timedelta(seconds=total_seconds) # Return as timedelta\n",
    "\n",
    "    return duration\n",
    "\n",
    "# Apply the conversion function to the 'duration' column\n",
    "lex_df0['duration'] = lex_df0['duration'].apply(convert_duration)\n",
    "\n",
    "# Create a new column 'duration_minutes' representing the duration in minutes\n",
    "lex_df0['duration_minutes'] = lex_df0['duration'].dt.total_seconds() / 60\n",
    "\n",
    "# Display the first rows of the updated DataFrame\n",
    "lex_df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type Conversion for Data Analysis and Consistency\n",
    "\n",
    "# Convert numerical statistics columns to integers\n",
    "lex_df0[['views', 'likes', 'comments_count', 'favorite_count']] = lex_df0[['views', 'likes', 'comments_count', 'favorite_count']].astype(int)\n",
    "\n",
    "# Convert duration in minutes to float (for potential fractional minutes)\n",
    "lex_df0['duration_minutes'] = lex_df0['duration_minutes'].astype(float)\n",
    "\n",
    "# Convert captions availability to boolean (True/False) for easier filtering/analysis\n",
    "lex_df0['captions_availability'] = lex_df0['captions_availability'].apply(lambda x: True if x.lower() == 'true' else False)\n",
    "\n",
    "# Convert upload dates to datetime objects for date/time-based operations\n",
    "lex_df0['upload_date'] = pd.to_datetime(lex_df0['upload_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get guest nationality and profession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll get the guests nationality and profession using `requests` in wikipedia pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This scraping operation took 55 seconds\n"
     ]
    }
   ],
   "source": [
    "# Record start time for performance measurement\n",
    "start = time.time()\n",
    "\n",
    "# Define a function to fetch guest nationality and profession from Wikipedia\n",
    "def fetch_bio_data(guest_name):\n",
    "    \"\"\"\n",
    "    Fetches biographical data (nationality and profession) for a given guest name from Wikipedia pages\n",
    "\n",
    "    Args:\n",
    "        guest_name (str): The name of the guest.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the guest's nationality and profession, or NaN values if not found.\n",
    "    \"\"\"\n",
    "    url = f\"https://en.wikipedia.org/api/rest_v1/page/summary/{guest_name.replace(' ', '_')}\" # Construct Wikipedia page URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200: # Check for successful response\n",
    "        data = response.json()\n",
    "        # Extract nationality and profession from the Wikipedia page summary (if available)\n",
    "        return {\n",
    "            'nationality': data.get('description', 'N/A').split(\", \")[-1] if 'description' in data else 'N/A', # Nationality is assumed to be the last element\n",
    "            'profession': data.get('description', 'N/A').split(\", \")[0] if 'description' in data else 'N/A' # Profession is assumed to be the first element\n",
    "        }\n",
    "    # Handle cases where the Wikipedia page is not found or other errors\n",
    "    else:\n",
    "        return {'nationality': np.nan, 'profession': np.nan}\n",
    "\n",
    "# Apply function to DataFrame and create new columns\n",
    "lex_df0[['nationality', 'profession']] = lex_df0['guest'].apply(lambda x: pd.Series(fetch_bio_data(x)))\n",
    "\n",
    "# Calculate and print execution time\n",
    "end = time.time()\n",
    "print(f'This scraping operation took {round(end - start)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guest</th>\n",
       "      <th>nationality</th>\n",
       "      <th>profession</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rick Spence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>American politician and activist (born 1941)</td>\n",
       "      <td>American politician and activist (born 1941)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Graham Hancock</td>\n",
       "      <td>British writer (born 1950)</td>\n",
       "      <td>British writer (born 1950)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jordan Peterson</td>\n",
       "      <td>Canadian clinical psychologist (born 1962)</td>\n",
       "      <td>Canadian clinical psychologist (born 1962)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cursor Team</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ed Barnhart</td>\n",
       "      <td>American archaeologist and explorer (born 1968)</td>\n",
       "      <td>American archaeologist and explorer (born 1968)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vivek Ramaswamy</td>\n",
       "      <td>American businessman (born 1985)</td>\n",
       "      <td>American businessman (born 1985)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Vejas Liulevicius</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gregory Aldrete</td>\n",
       "      <td>American academic</td>\n",
       "      <td>American academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Former president and president-elect of the Un...</td>\n",
       "      <td>Former president and president-elect of the Un...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               guest                                        nationality  \\\n",
       "0        Rick Spence                                                NaN   \n",
       "1     Bernie Sanders       American politician and activist (born 1941)   \n",
       "2     Graham Hancock                         British writer (born 1950)   \n",
       "3    Jordan Peterson         Canadian clinical psychologist (born 1962)   \n",
       "4        Cursor Team                                                NaN   \n",
       "5        Ed Barnhart    American archaeologist and explorer (born 1968)   \n",
       "6    Vivek Ramaswamy                   American businessman (born 1985)   \n",
       "7  Vejas Liulevicius                                                NaN   \n",
       "8    Gregory Aldrete                                  American academic   \n",
       "9       Donald Trump  Former president and president-elect of the Un...   \n",
       "\n",
       "                                          profession  \n",
       "0                                                NaN  \n",
       "1       American politician and activist (born 1941)  \n",
       "2                         British writer (born 1950)  \n",
       "3         Canadian clinical psychologist (born 1962)  \n",
       "4                                                NaN  \n",
       "5    American archaeologist and explorer (born 1968)  \n",
       "6                   American businessman (born 1985)  \n",
       "7                                                NaN  \n",
       "8                                  American academic  \n",
       "9  Former president and president-elect of the Un...  "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 10 rows of the newly added columns with the guest names\n",
    "lex_df0[['guest', 'nationality', 'profession']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After checking the profession and nationality columns, I found some inconsistencies and duplications between the two columns. So I'll handle those using regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refine nationality and profession extraction using regular expressions\n",
    "def split_nationality_profession(text):\n",
    "    \"\"\"\n",
    "    Splits a string into nationality and profession components using a regular expression.\n",
    "    Assumes nationality consists of capitalized words (including hyphenated) at the beginning of the string.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input string containing potential nationality and profession information.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: A Pandas Series containing the extracted nationality and profession.\n",
    "                   Returns empty strings if the input is not a string or no match is found.\n",
    "    \"\"\"\n",
    "    # Check if the input is a string\n",
    "    if isinstance(text, str):  # Check if the input is a valid string\n",
    "        # Regular expression to match capitalized words (or hyphenated capitalized words) at the beginning of the string\n",
    "        match = re.match(r'^([A-Z][a-z]*(?:-[A-Z][a-z]*)*\\s?)+', text)\n",
    "        if match:\n",
    "            nationality = match.group().strip()\n",
    "            profession = text[len(nationality):].strip()\n",
    "            return pd.Series([nationality, profession])\n",
    "    # Return empty strings if the text is not a valid string\n",
    "    return pd.Series([\"\", \"\"])\n",
    "\n",
    "# Apply the function to the 'profession' column to split it into separate 'nationality' and 'profession' columns\n",
    "lex_df0[['nationality', 'profession']] = lex_df0['profession'].apply(split_nationality_profession)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guest</th>\n",
       "      <th>nationality</th>\n",
       "      <th>profession</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rick Spence</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>American</td>\n",
       "      <td>politician and activist (born 1941)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Graham Hancock</td>\n",
       "      <td>British</td>\n",
       "      <td>writer (born 1950)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jordan Peterson</td>\n",
       "      <td>Canadian</td>\n",
       "      <td>clinical psychologist (born 1962)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cursor Team</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ed Barnhart</td>\n",
       "      <td>American</td>\n",
       "      <td>archaeologist and explorer (born 1968)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vivek Ramaswamy</td>\n",
       "      <td>American</td>\n",
       "      <td>businessman (born 1985)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Vejas Liulevicius</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gregory Aldrete</td>\n",
       "      <td>American</td>\n",
       "      <td>academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Former</td>\n",
       "      <td>president and president-elect of the United St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cenk Uygur</td>\n",
       "      <td>Turkish-American</td>\n",
       "      <td>political commentator (born 1970)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pieter Levels</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Craig Jones</td>\n",
       "      <td>Topics</td>\n",
       "      <td>referred to by the same term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>South African</td>\n",
       "      <td>-born businessman (born 1971)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Jordan Jonas</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ivanka Trump</td>\n",
       "      <td>American</td>\n",
       "      <td>businesswoman (born 1981)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Andrew Huberman</td>\n",
       "      <td>American</td>\n",
       "      <td>neuroscientist and podcaster (born 1975)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Aravind Srinivas</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sara Walker</td>\n",
       "      <td>American</td>\n",
       "      <td>theoretical physicist and astrobiologist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Kevin Spacey</td>\n",
       "      <td>American</td>\n",
       "      <td>actor (born 1959)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Roman Yampolskiy</td>\n",
       "      <td>Latvian</td>\n",
       "      <td>computer scientist (born 1979)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Charan Ranganath</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Paul Rosolie</td>\n",
       "      <td>American</td>\n",
       "      <td>conservationist and author</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Sean Carroll</td>\n",
       "      <td>Topics</td>\n",
       "      <td>referred to by the same term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Neil Adams</td>\n",
       "      <td>Topics</td>\n",
       "      <td>referred to by the same term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Edward Gibson</td>\n",
       "      <td>American</td>\n",
       "      <td>astronaut (born 1936)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Andrew Callaghan</td>\n",
       "      <td>American</td>\n",
       "      <td>journalist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Bassem Youssef</td>\n",
       "      <td>Egyptian-American</td>\n",
       "      <td>comedian and surgeon (born 1974)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Tulsi Gabbard</td>\n",
       "      <td>American</td>\n",
       "      <td>politician (born 1981)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Mark Cuban</td>\n",
       "      <td>American</td>\n",
       "      <td>businessman (born 1958)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                guest        nationality  \\\n",
       "0         Rick Spence                      \n",
       "1      Bernie Sanders           American   \n",
       "2      Graham Hancock            British   \n",
       "3     Jordan Peterson           Canadian   \n",
       "4         Cursor Team                      \n",
       "5         Ed Barnhart           American   \n",
       "6     Vivek Ramaswamy           American   \n",
       "7   Vejas Liulevicius                      \n",
       "8     Gregory Aldrete           American   \n",
       "9        Donald Trump             Former   \n",
       "10         Cenk Uygur   Turkish-American   \n",
       "11      Pieter Levels                      \n",
       "12        Craig Jones             Topics   \n",
       "13          Elon Musk      South African   \n",
       "14       Jordan Jonas                      \n",
       "15       Ivanka Trump           American   \n",
       "16    Andrew Huberman           American   \n",
       "17   Aravind Srinivas                      \n",
       "18        Sara Walker           American   \n",
       "19       Kevin Spacey           American   \n",
       "20   Roman Yampolskiy            Latvian   \n",
       "21   Charan Ranganath                      \n",
       "22       Paul Rosolie           American   \n",
       "23       Sean Carroll             Topics   \n",
       "24         Neil Adams             Topics   \n",
       "25      Edward Gibson           American   \n",
       "26   Andrew Callaghan           American   \n",
       "27     Bassem Youssef  Egyptian-American   \n",
       "28      Tulsi Gabbard           American   \n",
       "29         Mark Cuban           American   \n",
       "\n",
       "                                           profession  \n",
       "0                                                      \n",
       "1                 politician and activist (born 1941)  \n",
       "2                                  writer (born 1950)  \n",
       "3                   clinical psychologist (born 1962)  \n",
       "4                                                      \n",
       "5              archaeologist and explorer (born 1968)  \n",
       "6                             businessman (born 1985)  \n",
       "7                                                      \n",
       "8                                            academic  \n",
       "9   president and president-elect of the United St...  \n",
       "10                  political commentator (born 1970)  \n",
       "11                                                     \n",
       "12                       referred to by the same term  \n",
       "13                      -born businessman (born 1971)  \n",
       "14                                                     \n",
       "15                          businesswoman (born 1981)  \n",
       "16           neuroscientist and podcaster (born 1975)  \n",
       "17                                                     \n",
       "18           theoretical physicist and astrobiologist  \n",
       "19                                  actor (born 1959)  \n",
       "20                     computer scientist (born 1979)  \n",
       "21                                                     \n",
       "22                         conservationist and author  \n",
       "23                       referred to by the same term  \n",
       "24                       referred to by the same term  \n",
       "25                              astronaut (born 1936)  \n",
       "26                                         journalist  \n",
       "27                   comedian and surgeon (born 1974)  \n",
       "28                             politician (born 1981)  \n",
       "29                            businessman (born 1958)  "
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 30 rows\n",
    "lex_df0[['guest', 'nationality', 'profession']].head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this looks so much better, Now let's do some manual refinemnets and standardization into the **nationality** column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary to map incorrect or inconsistent nationality data to their standardized equivalents\n",
    "replacement_dict = {\n",
    "    \"President\": \"American\",\n",
    "    \"Retired United States Navy SEAL\": \"American\",\n",
    "    \"Israeli-American Objectivist\": \"Israeli-American\",\n",
    "    \"American AI\": \"American\",\n",
    "    \"Brazilian Jiu-Jitsu\": \"Brazilian\",\n",
    "    \"Australia\": \"Australian\",\n",
    "    \"Australian\": \"Australian\",\n",
    "    \"American YouTuber\": \"American\",\n",
    "    \"English-American\": \"British-American\",\n",
    "    \"English\": \"British\",\n",
    "    \"American-Swiss\": \"Swiss-American\",\n",
    "    \"French American\": \"French-American\",\n",
    "    \"Topics referred to by the same term\": 'N/A'\n",
    "}\n",
    "\n",
    "# Replace values in the 'nationality' column using the mapping dictionary\n",
    "lex_df0['nationality'] = lex_df0['nationality'].replace(replacement_dict)#, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do some regular expressions refinemnets and standardization into the **prefession** column, I'll remove the birth years too because they're not extracted for every guest, and I'll add them later for everyone using Wikidata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove birth year information from profession entries using a regular expression\n",
    "# \\s*: Matches zero or more whitespace characters\n",
    "# \\( and \\): Matches literal parentheses\n",
    "# born: Matches the literal word \"born\"\n",
    "# \\d{4}: Matches exactly four digits (the year)\n",
    "lex_df0['profession'] = lex_df0['profession'].str.replace(r'\\s*\\(born \\d{4}\\)', '', regex=True)\n",
    "\n",
    "# Remove leading/trailing whitespace from profession entries\n",
    "lex_df0['profession'] = lex_df0['profession'].str.strip()\n",
    "\n",
    "# Define a function to standardizes profession column\n",
    "def standardize_profession(profession):\n",
    "    \"\"\"\n",
    "    Standardizes profession strings by removing extra whitespace, birth year info, and parenthetical content.\n",
    "\n",
    "    Args:\n",
    "        profession (str or NaN): The profession string to standardize.\n",
    "\n",
    "    Returns:\n",
    "        str or NaN: The standardized profession string, or NaN if the input was NaN.\n",
    "    \"\"\"\n",
    "    if pd.isna(profession): # Handle missing values (NaN)\n",
    "        return profession\n",
    "        \n",
    "    profession = str(profession).lower().strip() # Convert to lowercase and remove leading/trailing whitespace\n",
    "    \n",
    "    # Remove the '-Born' prefix\n",
    "    profession = profession.replace('-born', '').strip()\n",
    "    profession = profession.replace('born', '').strip()\n",
    "    \n",
    "    # Remove parenthetical content (including anything inside parentheses)\n",
    "    profession = re.sub(r'\\s*\\(.*?\\)', '', profession) # Non-greedy matching to avoid capturing too much\n",
    "\n",
    "    # Remove content after an en dash (including the dash) – often used for birth/death dates or additional info\n",
    "    profession = re.sub(r'\\s*–.*', '', profession)\n",
    "    \n",
    "    return profession\n",
    "\n",
    "# Apply the standardization function to the 'profession' column\n",
    "lex_df0['profession'] = lex_df0['profession'].apply(standardize_profession)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually refine the profession column, I try as much as I can to make it just a single word to make the analysis easier\n",
    "\n",
    "# Define a dictionary to map incorrect or inconsistent profession data to their standardized equivalents\n",
    "profession_replacement_dict = {\n",
    "    \"-born businessman\": \"Businessperson\",\n",
    "    \"neuroscientist and podcaster\": \"Neuroscientist\",\n",
    "    \"computer scientist and mathematician\": \"Computer Scientist\",\n",
    "    \"podcaster and comedian\": \"Comedian\",\n",
    "    \"linguist and activist\": \"Linguist\",\n",
    "    \"philosopher and neuroscientist\": \"Philosopher\",\n",
    "    \"investor and hedge fund manager\": \"Investor\",\n",
    "    \"comedian and actor\": \"Comedian\",\n",
    "    \"entrepreneur and investor\": \"Entrepreneur\",\n",
    "    \"clinical psychologist\": \"Psychologist\",\n",
    "    \"wrestler and mixed martial artist\": \"Martial Arts\",\n",
    "    \"speculative fiction writer\": \"Writer\",\n",
    "    \"physician-scientist\": \"Scientist\",\n",
    "    \"astronomer and planetary scientist\": \"Astronomer\",\n",
    "    \"computer programmer and entrepreneur\": \"Computer Scientist\",\n",
    "    \"rapper and record producer\": \"Rapper\",\n",
    "    \"wrestler\": \"Martial Arts\",\n",
    "    \"chef and businessperson\": \"Chef\",\n",
    "    \"businessman and software engineer\": \"Businessperson\",\n",
    "    \"defector and activist\": \"Defector\",\n",
    "    \"evolutionary biologist and author\": \"Biologist\",\n",
    "    \"cognitive scientist\": \"Scientist\",\n",
    "    \"physicist and Nobel laureate\": \"Physicist\",\n",
    "    \"writer and director\": \"Writer\",\n",
    "    \"wrestler and coach\": \"Martial Arts\",\n",
    "    \"stand-up comedian and actor\": \"Comedian\",\n",
    "    \"moral philosopher\": \"Philosopher\",\n",
    "    \"mathematical physicist\": \"Physicist\",\n",
    "    \"businessman and investor\": \"Businessperson\",\n",
    "    \"politician and activist\": \"Politician\",\n",
    "    \"social psychologist\": \"Psychologist\",\n",
    "    \"professional armwrestler\": \"Martial Arts\",\n",
    "    \"political scientist\": \"Scientist\",\n",
    "    \"and businessman\": \"Businessperson\",\n",
    "    \"businessman and author\": \"Businessperson\",    \n",
    "    \"researcher and writer\": \"Writer\",\n",
    "    \"designer and academic\": \"Designer\",\n",
    "    \"Investigative journalist and author\": \"Journalist\",\n",
    "    \"chess grandmaster and streamer\": \"Chess Player\",\n",
    "    \"comedian and surgeon\": \"Comedian\",\n",
    "    \"businesswoman\": \"Businessperson\",\n",
    "    \"archaeologist and explorer\": \"Archaeologist\",\n",
    "    \"-born AI researcher\": \"AI Expert\",\n",
    "    \"chess player and content creator\": \"Chess Player\",    \n",
    "    \"record producer\": \"Producer\",\n",
    "    \"evolutionary psychologist\": \"Psychologist\",\n",
    "    \"artificial intelligence researcher\": \"AI Expert\",\n",
    "    \"economist and author\": \"Economist\",\n",
    "    \"cosmologist and astrophysicist\": \"Astrophysicist\",\n",
    "    \"computer programmer and video game developer\": \"Computer Scientist\",\n",
    "    \"chess grandmaster\": \"Chess Player\",\n",
    "    \"biochemist and writer\": \"Biochemist\",\n",
    "    \"software engineer\": \"Computer Scientist\",\n",
    "    \"-Founder Of Wikipedia\": \"Founder Of Wikipedia\",\n",
    "    \"And Writer\": \"Writer\",\n",
    "    \"Physician\": \"Physicist\",\n",
    "    \"Programmer\": \"Computer Scientist\",\n",
    "    \"Business Executive\": \"Businessperson\",\n",
    "    \"ai scientist\": \"AI Expert\",\n",
    "    \"anthropologist and primatologist\": \"Anthropologist\",\n",
    "    \"anti-scientology activist\": \"Activist\",\n",
    "    \"Archaeologist And Explorer\": \"Archaeologist\",\n",
    "    \"astronautical engineer\": \"Engineer\",\n",
    "    \"astronomer and associate professor\": \"Astronomer\",\n",
    "    \"Astronomer And Planetary Scientist\": \"Astronomer\",\n",
    "    \"author and motivational speaker\": \"Author\",\n",
    "    \"author and producer\": \"Author\",\n",
    "    \"billionaire hedge fund manager  1966\": \"Investor\",\n",
    "    \"business executive\": \"Businessperson\",\n",
    "    \"businessman\": \"Businessperson\",\n",
    "    \"businessperson and author\": \"Businessperson\",\n",
    "    \"businesswoman\": \"Businessperson\",\n",
    "    \"Chef And Businessperson\": \"Chef\",\n",
    "    \"Investigative Journalist\": \"Journalist\",    \n",
    "    \"aerospace engineer\": \"Engineer\",\n",
    "    \"ai researcher\": \"AI Expert\",\n",
    "    \"co-founders of fermat’s library\": \"Co-Founder\",\n",
    "    \"computer scientist and ai researcher\": \"Computer Scientist\",\n",
    "    \"computer scientist and technology executive\": \"Computer Scientist\",\n",
    "    \"conservationist and author\": \"Conservationist\",    \n",
    "    \"cryptocurrency entrepreneur\": \"Entrepreneur\",\n",
    "    \"economist and political scientist\": \"Economist\",    \n",
    "    \"free speech advocate\": \"Attorney\",    \n",
    "    \"geopolitical commentator and author\": \"Political Commentator\",\n",
    "    \"international rugby league footballer\": \"Footballer\",\n",
    "    \"inventor and robotics youtuber\": \"Inventor\",\n",
    "    \"investigative journalist and author\": \"Journalist\",\n",
    "    \"legal scholar\": \"Scholar\",    \n",
    "    \"machine learning researcher\": \"AI Expert\",\n",
    "    \"mathematics educator\": \"Mathematician\",\n",
    "    \"mixed martial artist and professional wrestler\": \"Martial Arts\",\n",
    "    \"mixed martial arts fighter\": \"Martial Arts\",\n",
    "    \"molecular biologist\": \"Biologist\",    \n",
    "    \"multimedia instant messaging app\": \"Entrepreneur\",\n",
    "    \"of wellesley college\": \"Professor\",\n",
    "    \"particle physicist\": \"Physicist\",\n",
    "    \"philanthropic organization\": \"Activist\",\n",
    "    \"philosopher and cognitive scientist\": \"Philosopher\",\n",
    "    \"physician and author\": \"Physician\",\n",
    "    \"physicist and computational neuroscientist\": \"Physicist\",\n",
    "    \"physicist and nobel laureate\": \"Physicist\",\n",
    "    \"planetary physicist\": \"Physicist\",\n",
    "    \"podcaster and author\": \"Podcaster\",\n",
    "    \"political pundit\": \"Political Commentator\",\n",
    "    \"practitioner and mixed martial artist\": \"Martial Arts\",\n",
    "    \"software developer\": \"Computer Scientist\",\n",
    "    \"technology company that produces consumer robots\": \"Roboticist\",\n",
    "    \"theoretical physicist and astrobiologist\": \"Physicist\",\n",
    "    \"ultramarathon runner\": \"Athlete\",\n",
    "    \"writer and media personality\": \"Writer\",\n",
    "    \"film producer\": \"Producer\",\n",
    "    \"filmmaker\": \"Director\",\n",
    "    \"Film Producer\": \"Producer\",\n",
    "    \"Film Director\": \"Director\",\n",
    "    \"musician\": \"Artist\",\n",
    "    \"game designer\": \"Designer\",\n",
    "    \"judoka\": \"Martial Arts\",\n",
    "    \"singer\": \"Artist\",\n",
    "    \"programmer\": \"Computer Scientist\",\n",
    "    \"theoretical physicist\": \"Physicist\",\n",
    "    \"computational biologist\": \"Biologist\",\n",
    "    \"research scientist\": \"Researcher\",\n",
    "    \"lawyer\": \"Attorney\"\n",
    "}\n",
    "\n",
    "# Replace values in the 'profession' column using the mapping dictionary\n",
    "lex_df0['profession'] = lex_df0['profession'].replace(profession_replacement_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guest</th>\n",
       "      <th>nationality</th>\n",
       "      <th>profession</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rick Spence</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>American</td>\n",
       "      <td>Politician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Graham Hancock</td>\n",
       "      <td>British</td>\n",
       "      <td>writer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jordan Peterson</td>\n",
       "      <td>Canadian</td>\n",
       "      <td>Psychologist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cursor Team</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ed Barnhart</td>\n",
       "      <td>American</td>\n",
       "      <td>Archaeologist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vivek Ramaswamy</td>\n",
       "      <td>American</td>\n",
       "      <td>Businessperson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Vejas Liulevicius</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gregory Aldrete</td>\n",
       "      <td>American</td>\n",
       "      <td>academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Former</td>\n",
       "      <td>president and president-elect of the united st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cenk Uygur</td>\n",
       "      <td>Turkish-American</td>\n",
       "      <td>political commentator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pieter Levels</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Craig Jones</td>\n",
       "      <td>Topics</td>\n",
       "      <td>referred to by the same term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>South African</td>\n",
       "      <td>Businessperson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Jordan Jonas</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ivanka Trump</td>\n",
       "      <td>American</td>\n",
       "      <td>Businessperson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Andrew Huberman</td>\n",
       "      <td>American</td>\n",
       "      <td>Neuroscientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Aravind Srinivas</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sara Walker</td>\n",
       "      <td>American</td>\n",
       "      <td>Physicist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Kevin Spacey</td>\n",
       "      <td>American</td>\n",
       "      <td>actor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Roman Yampolskiy</td>\n",
       "      <td>Latvian</td>\n",
       "      <td>computer scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Charan Ranganath</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Paul Rosolie</td>\n",
       "      <td>American</td>\n",
       "      <td>Conservationist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Sean Carroll</td>\n",
       "      <td>Topics</td>\n",
       "      <td>referred to by the same term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Neil Adams</td>\n",
       "      <td>Topics</td>\n",
       "      <td>referred to by the same term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Edward Gibson</td>\n",
       "      <td>American</td>\n",
       "      <td>astronaut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Andrew Callaghan</td>\n",
       "      <td>American</td>\n",
       "      <td>journalist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Bassem Youssef</td>\n",
       "      <td>Egyptian-American</td>\n",
       "      <td>Comedian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Tulsi Gabbard</td>\n",
       "      <td>American</td>\n",
       "      <td>politician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Mark Cuban</td>\n",
       "      <td>American</td>\n",
       "      <td>Businessperson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                guest        nationality  \\\n",
       "0         Rick Spence                      \n",
       "1      Bernie Sanders           American   \n",
       "2      Graham Hancock            British   \n",
       "3     Jordan Peterson           Canadian   \n",
       "4         Cursor Team                      \n",
       "5         Ed Barnhart           American   \n",
       "6     Vivek Ramaswamy           American   \n",
       "7   Vejas Liulevicius                      \n",
       "8     Gregory Aldrete           American   \n",
       "9        Donald Trump             Former   \n",
       "10         Cenk Uygur   Turkish-American   \n",
       "11      Pieter Levels                      \n",
       "12        Craig Jones             Topics   \n",
       "13          Elon Musk      South African   \n",
       "14       Jordan Jonas                      \n",
       "15       Ivanka Trump           American   \n",
       "16    Andrew Huberman           American   \n",
       "17   Aravind Srinivas                      \n",
       "18        Sara Walker           American   \n",
       "19       Kevin Spacey           American   \n",
       "20   Roman Yampolskiy            Latvian   \n",
       "21   Charan Ranganath                      \n",
       "22       Paul Rosolie           American   \n",
       "23       Sean Carroll             Topics   \n",
       "24         Neil Adams             Topics   \n",
       "25      Edward Gibson           American   \n",
       "26   Andrew Callaghan           American   \n",
       "27     Bassem Youssef  Egyptian-American   \n",
       "28      Tulsi Gabbard           American   \n",
       "29         Mark Cuban           American   \n",
       "\n",
       "                                           profession  \n",
       "0                                                      \n",
       "1                                          Politician  \n",
       "2                                              writer  \n",
       "3                                        Psychologist  \n",
       "4                                                      \n",
       "5                                       Archaeologist  \n",
       "6                                      Businessperson  \n",
       "7                                                      \n",
       "8                                            academic  \n",
       "9   president and president-elect of the united st...  \n",
       "10                              political commentator  \n",
       "11                                                     \n",
       "12                       referred to by the same term  \n",
       "13                                     Businessperson  \n",
       "14                                                     \n",
       "15                                     Businessperson  \n",
       "16                                     Neuroscientist  \n",
       "17                                                     \n",
       "18                                          Physicist  \n",
       "19                                              actor  \n",
       "20                                 computer scientist  \n",
       "21                                                     \n",
       "22                                    Conservationist  \n",
       "23                       referred to by the same term  \n",
       "24                       referred to by the same term  \n",
       "25                                          astronaut  \n",
       "26                                         journalist  \n",
       "27                                           Comedian  \n",
       "28                                         politician  \n",
       "29                                     Businessperson  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 30 rows\n",
    "lex_df0[['guest', 'nationality', 'profession']].head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get guest birth and death years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll get the guests birth and death years using `requests` in wikidata pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This scraping operation took 302 seconds\n"
     ]
    }
   ],
   "source": [
    "# Record start time for performance measurement\n",
    "start = time.time()\n",
    "\n",
    "def get_birth_death_years(name):\n",
    "    \"\"\"\n",
    "    Queries Wikidata for the birth and death years of guest names.\n",
    "\n",
    "    Args:\n",
    "        name (str): The name of the guest to search for.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the birth year and death year (as strings), or (None, None) if not found or an error occurs.\n",
    "    \"\"\"\n",
    "    url = f\"https://www.wikidata.org/w/api.php?action=wbsearchentities&search={name}&language=en&format=json\" # Construct Wikidata page URL\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        \n",
    "        if data['search']: # Check if any search results were returned\n",
    "            entity_id = data['search'][0]['id'] # Get the Wikidata entity ID of the first result (most likely match)\n",
    "\n",
    "            # Construct the Wikidata URL to get claims (properties) for the entity\n",
    "            details_url = f\"https://www.wikidata.org/w/api.php?action=wbgetclaims&entity={entity_id}&format=json\"\n",
    "            details_response = requests.get(details_url)\n",
    "            details_data = details_response.json()\n",
    "            \n",
    "            birth_year = death_year = None\n",
    "            \n",
    "            # Extract birth year (property P569)\n",
    "            if 'P569' in details_data['claims']:\n",
    "                birth_date = details_data['claims']['P569'][0]['mainsnak']['datavalue']['value']['time']\n",
    "                birth_year = birth_date[1:5]  # Extract the year from the date string\n",
    "\n",
    "            # Extract death year (property P570)    \n",
    "            if 'P570' in details_data['claims']:\n",
    "                death_date = details_data['claims']['P570'][0]['mainsnak']['datavalue']['value']['time']\n",
    "                death_year = death_date[1:5]  # Extract the year from the date string\n",
    "            \n",
    "            return birth_year, death_year\n",
    "    except Exception as e: # Handle any errors during the process\n",
    "        print(f\"Error retrieving data for {name}: {e}\")\n",
    "        return None, None # Return None values if an error occurred\n",
    "    \n",
    "# Apply the function to the 'guest' column to create new 'birth_year' and 'death_year' columns\n",
    "lex_df0[['birth_year', 'death_year']] = lex_df0['guest'].apply(lambda name: pd.Series(get_birth_death_years(name)))\n",
    "\n",
    "# Calculate and print execution time\n",
    "end = time.time()\n",
    "print(f'This scraping operation took {round(end - start)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert birth and death years into integers\n",
    "lex_df0['birth_year'] = lex_df0['birth_year'].fillna(0).astype(int)\n",
    "lex_df0['death_year'] = lex_df0['death_year'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guest</th>\n",
       "      <th>nationality</th>\n",
       "      <th>profession</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>death_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>Vladimir Vapnik</td>\n",
       "      <td>Russian</td>\n",
       "      <td>mathematician</td>\n",
       "      <td>1936</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>Yoshua Bengio</td>\n",
       "      <td>Canadian</td>\n",
       "      <td>computer scientist</td>\n",
       "      <td>1964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>Steven Pinker</td>\n",
       "      <td>Canadian-American</td>\n",
       "      <td>psycholinguist</td>\n",
       "      <td>1954</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>Christof Koch</td>\n",
       "      <td>German-American</td>\n",
       "      <td>neurophysiologist</td>\n",
       "      <td>1956</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>Max Tegmark</td>\n",
       "      <td>Swedish-American</td>\n",
       "      <td>cosmologist</td>\n",
       "      <td>1967</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>Andrew Bustamante</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>Tucker Carlson</td>\n",
       "      <td>American</td>\n",
       "      <td>political commentator</td>\n",
       "      <td>1969</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>Jordan Peterson</td>\n",
       "      <td>Canadian</td>\n",
       "      <td>Psychologist</td>\n",
       "      <td>1962</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>South African</td>\n",
       "      <td>Businessperson</td>\n",
       "      <td>1971</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>Paul Rosolie</td>\n",
       "      <td>American</td>\n",
       "      <td>Conservationist</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>Ben Shapiro</td>\n",
       "      <td>American</td>\n",
       "      <td>political commentator</td>\n",
       "      <td>1984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>David Kipping</td>\n",
       "      <td>British-American</td>\n",
       "      <td>Astronomer</td>\n",
       "      <td>1980</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>South African</td>\n",
       "      <td>Businessperson</td>\n",
       "      <td>1971</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>Joe Rogan</td>\n",
       "      <td>American</td>\n",
       "      <td>Comedian</td>\n",
       "      <td>1967</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>Michael Saylor</td>\n",
       "      <td>American</td>\n",
       "      <td>Businessperson</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>Donald Hoffman</td>\n",
       "      <td>Topics</td>\n",
       "      <td>referred to by the same term</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>Brett Johnson</td>\n",
       "      <td>Topics</td>\n",
       "      <td>referred to by the same term</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>Coffeezilla</td>\n",
       "      <td>American</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>Ben Shapiro</td>\n",
       "      <td>American</td>\n",
       "      <td>political commentator</td>\n",
       "      <td>1984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>Nick Lane</td>\n",
       "      <td>British</td>\n",
       "      <td>Biochemist</td>\n",
       "      <td>1967</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>Brian Keating</td>\n",
       "      <td>American</td>\n",
       "      <td>cosmologist</td>\n",
       "      <td>1971</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>John Mearsheimer</td>\n",
       "      <td>American</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>1947</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>Sam Harris</td>\n",
       "      <td>American</td>\n",
       "      <td>Philosopher</td>\n",
       "      <td>1967</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>Dan Carlin</td>\n",
       "      <td>American</td>\n",
       "      <td>podcaster</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>David Fravor</td>\n",
       "      <td>Cockpit</td>\n",
       "      <td>instrumentation display videos from us navy fi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>Sam Altman</td>\n",
       "      <td>American</td>\n",
       "      <td>Entrepreneur</td>\n",
       "      <td>1985</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>Jack Barsky</td>\n",
       "      <td>German-American</td>\n",
       "      <td>author</td>\n",
       "      <td>1949</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Former</td>\n",
       "      <td>president and president-elect of the united st...</td>\n",
       "      <td>1946</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>Garry Nolan</td>\n",
       "      <td>American</td>\n",
       "      <td>academic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>Avi Loeb</td>\n",
       "      <td>Israeli-American</td>\n",
       "      <td>Physicist</td>\n",
       "      <td>1962</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 guest        nationality  \\\n",
       "444    Vladimir Vapnik            Russian   \n",
       "445      Yoshua Bengio           Canadian   \n",
       "446      Steven Pinker  Canadian-American   \n",
       "447      Christof Koch    German-American   \n",
       "448        Max Tegmark   Swedish-American   \n",
       "449  Andrew Bustamante                      \n",
       "450     Tucker Carlson           American   \n",
       "451    Jordan Peterson           Canadian   \n",
       "452          Elon Musk      South African   \n",
       "453       Paul Rosolie           American   \n",
       "454        Ben Shapiro           American   \n",
       "455      David Kipping   British-American   \n",
       "456          Elon Musk      South African   \n",
       "457          Joe Rogan           American   \n",
       "458     Michael Saylor           American   \n",
       "459     Donald Hoffman             Topics   \n",
       "460      Brett Johnson             Topics   \n",
       "461        Coffeezilla           American   \n",
       "462        Ben Shapiro           American   \n",
       "463          Nick Lane            British   \n",
       "464      Brian Keating           American   \n",
       "465   John Mearsheimer           American   \n",
       "466         Sam Harris           American   \n",
       "467         Dan Carlin           American   \n",
       "468       David Fravor            Cockpit   \n",
       "469         Sam Altman           American   \n",
       "470        Jack Barsky    German-American   \n",
       "471       Donald Trump             Former   \n",
       "472        Garry Nolan           American   \n",
       "473           Avi Loeb   Israeli-American   \n",
       "\n",
       "                                            profession  birth_year  death_year  \n",
       "444                                      mathematician        1936           0  \n",
       "445                                 computer scientist        1964           0  \n",
       "446                                     psycholinguist        1954           0  \n",
       "447                                  neurophysiologist        1956           0  \n",
       "448                                        cosmologist        1967           0  \n",
       "449                                                              0           0  \n",
       "450                              political commentator        1969           0  \n",
       "451                                       Psychologist        1962           0  \n",
       "452                                     Businessperson        1971           0  \n",
       "453                                    Conservationist           0           0  \n",
       "454                              political commentator        1984           0  \n",
       "455                                         Astronomer        1980           0  \n",
       "456                                     Businessperson        1971           0  \n",
       "457                                           Comedian        1967           0  \n",
       "458                                     Businessperson        1965           0  \n",
       "459                       referred to by the same term        1955           0  \n",
       "460                       referred to by the same term           0           0  \n",
       "461                                                              0           0  \n",
       "462                              political commentator        1984           0  \n",
       "463                                         Biochemist        1967           0  \n",
       "464                                        cosmologist        1971           0  \n",
       "465                                          Scientist        1947           0  \n",
       "466                                        Philosopher        1967           0  \n",
       "467                                          podcaster        1965           0  \n",
       "468  instrumentation display videos from us navy fi...           0           0  \n",
       "469                                       Entrepreneur        1985           0  \n",
       "470                                             author        1949           0  \n",
       "471  president and president-elect of the united st...        1946           0  \n",
       "472                                           academic           0           0  \n",
       "473                                          Physicist        1962           0  "
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the last 30 rows of the newly added columns with the guest names\n",
    "lex_df0[['guest', 'nationality', 'profession', 'birth_year', 'death_year']].tail(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final manual refinements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I have to do some manual refinements on the whole dataset, on guest\tnationality, profession, birth_year, and death_year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As some guests birth years are not available on the internet, I'll do some estimation based on their education and careers, and indicate that with a boolean column if it's estimated or not\n",
    "lex_df0['birth_year_estimated'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual refining of guests’ biographic data\n",
    "\n",
    "lex_df0.loc[lex_df0['guest'] == 'Bernie Sanders', ['profession']] = ['Politician']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Mohammed El-Kurd', ['profession']] = ['Activist']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Noam Chomsky', ['profession']] = ['Activist']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Rick Doblin', ['profession']] = ['Researcher']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Yeonmi Park', ['profession']] = ['Activist']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Marcus Hutter', ['nationality', 'profession']] = ['German', 'AI Expert']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Harvey Silverglate', ['nationality', 'profession']] = ['American', 'Attorney']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Albert Bourla', ['nationality', 'profession']] = ['Greek-American', 'Businessperson']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Chris Urmson', ['nationality', 'profession']] = ['Canadian', 'Engineer']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Marc Raibert', ['nationality', 'profession']] = ['American', 'Engineer']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Marc Andreessen', ['nationality', 'profession']] = ['American', 'Entrepreneur']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Douglas Lenat', ['nationality', 'profession']] = ['American', 'Computer Scientist']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Ilya Sutskever', ['nationality', 'profession']] = ['Israeli-Canadian', 'Computer Scientist']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Judea Pearl', ['nationality', 'profession']] = ['Israeli-American', 'Computer Scientist']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Cristiano Amon', ['nationality', 'profession']] = ['Brazilian', 'Engineer']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Bjørn Lomborg and Andrew Revkin', ['nationality', 'profession']] = ['Mixed', 'Mixed']\n",
    "lex_df0.loc[lex_df0['guest'] == 'David Ferrucci', ['nationality', 'profession', 'birth_year']] = ['American', 'Computer Scientist', 1970]\n",
    "lex_df0.loc[lex_df0['guest'] == 'François Chollet', ['nationality', 'profession']] = ['French', 'Computer Scientist']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Pieter Abbeel', ['nationality', 'profession']] = ['Belgian-American', 'Computer Scientist']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Grant Sanderson', ['nationality', 'profession', 'birth_year']] = ['American', 'YouTuber', 1997]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Aella', ['nationality', 'profession', 'birth_year','death_year']] = ['American', 'Sex Worker', 1992, 0]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Nick Bostrom', ['nationality', 'profession']] = ['Swedish', 'Philosopher']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Destiny', ['nationality', 'profession', 'birth_year']] = ['American', 'Streamer', 1988]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Clara Sousa-Silva', ['nationality', 'profession', 'birth_year', 'birth_year_estimated']] = ['Portuguese', 'Astrophysicist', 1985, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Andrew Callaghan', ['nationality', 'profession']] = ['American', 'YouTuber']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Cursor Team', ['nationality', 'profession']] = ['Mixed', 'Computer Scientist']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Lisa Feldman', ['nationality', 'profession']] = ['Canadian-American', 'Psychologist']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Charles Isbell', ['nationality', 'profession']] = ['American', 'Computer Scientist']\n",
    "lex_df0.loc[lex_df0['guest'] == 'John Clarke', ['nationality', 'profession']] = ['American', 'Martial Arts']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Matthew Johnson', ['nationality', 'profession']] = ['American', 'Psychologist']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Vejas Liulevicius', ['nationality', 'profession', 'birth_year']] = ['American', 'Historian', 1968]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Ryan Hall', ['nationality', 'profession']] = ['American', 'Martial Arts']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Aaron Smith-Levin', ['nationality', 'profession', 'birth_year']] = ['American', 'Activist', 1981]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Sara Walker', ['nationality', 'profession', 'birth_year', 'birth_year_estimated']] = ['American', 'Activist', 1982, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Alien Debate', ['guest', 'nationality', 'profession']] = ['Sara Walker and Lee Cronin', 'Mixed', 'Mixed']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Anca Dragan', ['nationality', 'profession', 'birth_year', 'birth_year_estimated']] = ['Romanian', 'Professor', 1986, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Aravind Srinivas', ['nationality', 'profession', 'birth_year', 'birth_year_estimated']] = ['Indian-American', 'Computer Scientist', 1994, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'B-Team Jiu', ['guest', 'nationality', 'profession']] = ['Craig Jones, Nicky Rod, and Nicky Ryan', 'Mixed', 'Martial Arts']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Balaji Srinivasan', ['nationality', 'profession', 'birth_year']] = ['American', 'Entrepreneur', 1980]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Benjamin Netanyahu', ['nationality', 'profession']] = ['Israeli', 'Politician, War Criminal']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Bishop Robert', ['guest', 'nationality', 'profession', 'birth_year', 'death_year']] = ['Bishop Robert Barron', 'American', 'Bishop', 1959, 0]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Bjarne Stroustrup', ['nationality', 'profession']] = ['Danish', 'Computer Scientist']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Boris Sofman', ['nationality', 'profession', 'birth_year', 'birth_year_estimated']] = ['American', 'Engineer', 1982, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Botez Sisters', ['guest', 'nationality', 'profession']] = ['Botez Sisters (Alexandra and Andrea Botez)', 'Canadian', 'Chess Player']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Brian Armstrong', ['nationality', 'profession']] = ['American', 'Businessperson']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Brian Muraresku', ['nationality', 'profession', 'birth_year']] = ['American', 'Author', 1984]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Charan Ranganath', ['nationality', 'profession', 'birth_year']] = ['Indian-American', 'Psychologist', 1971]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Chris Duffin', ['nationality', 'profession', 'birth_year']] = ['American', 'Entrepreneur', 1977]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Chris Mason', ['nationality', 'profession']] = ['American', 'Professor']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Chris Tarbell', ['nationality', 'profession', 'birth_year', 'birth_year_estimated']] = ['American', 'Former Intelligence Officer', 1977, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Christopher Capozzola', ['nationality', 'profession', 'birth_year', 'birth_year_estimated']] = ['American', 'Professor', 1972, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Craig Jones', ['nationality', 'profession', 'birth_year']] = ['Australian', 'Martial Arts', 1991]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Cristos Goodrow', ['nationality', 'profession', 'birth_year', 'birth_year_estimated']] = ['American', 'Computer Scientist', 1969, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Dan Kokotov', ['nationality', 'profession', 'birth_year']] = ['Russian-American', 'Computer Scientist', 1978]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Dan Reynolds', ['nationality', 'profession']] = ['American', 'Artist']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Daniel Schmachtenberger', ['nationality', 'profession', 'birth_year']] = ['American', 'Philosopher', 1984]\n",
    "lex_df0.loc[lex_df0['guest'] == 'David Eagleman', ['nationality', 'profession']] = ['American', 'Neuroscientist']\n",
    "lex_df0.loc[lex_df0['guest'] == 'David Patterson', ['nationality', 'profession']] = ['American', 'Computer Scientist']\n",
    "lex_df0.loc[lex_df0['guest'] == 'David Silver', ['nationality', 'profession', 'birth_year']] = ['British', 'Computer Scientist', 1976]\n",
    "lex_df0.loc[lex_df0['guest'] == 'David Sinclair', ['nationality', 'profession']] = ['Australian-American', 'Geneticist']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Dennis Whyte', ['nationality', 'profession']] = ['Canadian-American', 'Nuclear Scientist']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Dileep George', ['nationality', 'profession']] = ['Indian-American', 'AI Expert']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Dmitry Korkin', ['nationality', 'profession', 'birth_year']] = ['Russian-American', 'Professor', 1979]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Douglas Murray', ['nationality', 'profession', 'birth_year', 'death_year']] = ['British', 'Political Commentator', 1979, 0]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Ed Calderon', ['nationality', 'profession', 'birth_year']] = ['Mexican', 'Security Specialist', 1982]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Eugenia Kuyda', ['nationality', 'profession', 'birth_year']] = ['Russian-American', 'Entrepreneur', 1987]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Fiona Hill', ['nationality', 'profession']] = ['British-American', 'Political Advisor']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Glenn Loury', ['nationality', 'profession']] = ['American', 'Professor']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Greg Brockman', ['nationality', 'profession']] = ['American', 'Computer Scientist']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Guido van', ['guest', 'nationality', 'profession']] = ['Guido van Rossum', 'Dutch', 'Creator of Python Programming Language']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Guillaume Verdon', ['nationality', 'profession', 'birth_year', 'birth_year_estimated']] = ['French', 'Entrepreneur', 1990, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Gustav Soderstrom', ['nationality', 'profession', 'birth_year', 'birth_year_estimated']] = ['Swedish', 'Electrical Engineer', 1977, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Harry Cliff', ['nationality', 'profession', 'birth_year']] = ['British', 'Particle Physicist', 1985]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Ian Hutchinson', ['nationality', 'profession']] = ['British', 'Nuclear Engineer']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Ishan Misra', ['nationality', 'profession', 'birth_year', 'birth_year_estimated']] = ['Indian', 'Researcher    ', 1990, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Israel-Palestine Debate', ['guest', 'nationality', 'profession']] = ['Norman Finkelstein, Destiny, M. Rabbani & Benny Morris', 'Mixed', 'Mixed'] \n",
    "lex_df0.loc[lex_df0['guest'] == 'Jack Barsky', ['nationality', 'profession']] = ['German-American', 'Former Intelligence Officer']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Jack Dorsey', ['nationality', 'profession']] = ['American', 'Computer Scientist']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Jaron Lanier', ['nationality', 'profession']] = ['American', 'Computer Scientist']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Jay McClelland', ['nationality', 'profession']] = ['American', 'Cognitive Scientist']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Jeffrey Shainline', ['nationality', 'profession', 'birth_year', 'birth_year_estimated']] = ['American', 'Physicist', 1980, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Jeremy Howard', ['nationality', 'profession', 'birth_year']] = ['Australian', 'Data Scientist', 1973]\n",
    "lex_df0.loc[lex_df0['guest'] == 'John Danaher', ['nationality', 'profession']] = ['New Zealander', 'Martial Arts']\n",
    "lex_df0.loc[lex_df0['guest'] == 'John Vervaeke', ['nationality', 'profession', 'birth_year']] = ['Canadian', 'Psychologist', 1963]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Kai-Fu Lee', ['nationality', 'profession']] = ['Chinese-American', 'AI Expert']\n",
    "lex_df0.loc[lex_df0['guest'] == \"Kanye 'Ye'\", ['nationality', 'profession', 'birth_year']] = ['American', 'Artist', 1977]\n",
    "lex_df0.loc[lex_df0['guest'] == \"Katherine de\", ['guest', 'nationality', 'profession', 'birth_year', 'death_year']] = ['Katherine de Kleer', 'American', 'Scientist', 1987, 0]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Kelsi Sheren', ['nationality', 'profession', 'birth_year', 'birth_year_estimated']] = ['Canadian', 'Veteran', 1990, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Keoki Jackson', ['nationality', 'profession', 'birth_year', 'birth_year_estimated']] = ['American', 'Lockheed Martin Executive', 1970, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Kevin Scott', ['nationality', 'profession']] = ['American', 'Computer Scientist']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Lee Cronin', ['nationality', 'profession']] = ['British', 'Chemist']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Jeff Hawkins', ['nationality', 'profession']] = ['British', 'Chemist']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Liv Boeree', ['nationality', 'profession']] = ['British', 'Poker Player']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Luís and', ['guest', 'nationality', 'profession', 'birth_year', 'death_year']] = ['Luís and João Batalha', 'Portuguese', \"Co-founder\", 0, 0]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Magatte Wade', ['nationality', 'profession']] = ['Senegalese', 'Entrepreneur']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Matt Botvinick', ['nationality', 'profession', 'birth_year']] = ['American', 'AI Expert', 1968]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Matt Walker', ['nationality', 'profession']] = ['American', 'Scientist']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Matthew Cox', ['nationality', 'profession', 'birth_year']] = ['American', 'Former Con Man', 1969]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Michael Levin', ['nationality', 'profession']] = ['American', 'Professor']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Michael Malice', ['nationality', 'profession']] = ['American', 'Professor']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Michael Stevens', ['nationality', 'profession', 'birth_year']] = ['American', 'YouTuber', 1986]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Michio Kaku', ['nationality', 'profession']] = ['Japanese-American', 'Physicist']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Natalya Bailey', ['nationality', 'profession']] = ['Russian-American', 'Rocket Propulsion Engineer']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Neil Adams', ['nationality', 'profession']] = ['British', 'Martial Arts']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Nic Carter', ['nationality', 'profession', 'birth_year', 'birth_year_estimated']] = ['American', 'Researcher', 1990, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Nicole Perlroth', ['nationality', 'profession', 'birth_year']] = ['American', 'Journalist', 1981]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Noam Brown', ['nationality', 'profession', 'birth_year', 'birth_year_estimated']] = ['American', 'Researcher', 1988, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Omar Suleiman', ['nationality', 'profession', 'birth_year', 'death_year']] = ['Palestinian-American', 'Imam', 1986, 0]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Paul Conti', ['nationality', 'profession', 'birth_year']] = ['American', 'Psychiatrist', 1946]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Paul Goff', ['nationality', 'profession']] = ['British', 'Philosopher']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Pieter Levels', ['nationality', 'profession', 'birth_year']] = ['Dutch', 'Entrepreneur', 1986]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Rajat Monga', ['nationality', 'profession', 'birth_year', 'birth_year_estimated']] = ['Indian-American', 'Electrical Engineer', 1974, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Ray Kurzweil', ['nationality', 'profession']] = ['American', 'Inventor']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Risto Miikkulainen', ['nationality', 'profession']] = ['American', 'Entrepreneur']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Robert Crews', ['nationality', 'profession']] = ['American', 'Historian']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Robert F.', ['guest', 'nationality', 'profession', 'birth_year', 'death_year']] = ['Robert F. Kennedy Jr', 'American', 'Politician', 1954, 0]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Robert Playter', ['nationality', 'profession', 'birth_year', 'birth_year_estimated']] = ['American', 'Roboticist', 1970, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Rodney Brooks', ['nationality', 'profession']] = ['American', 'Historian']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Rohit Prasad', ['nationality', 'profession', 'birth_year']] = ['Indian', 'AI Expert', 1975]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Ronald Sullivan', ['nationality', 'profession', 'birth_year']] = ['American', 'Professor', 1967]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Russ Tedrake', ['nationality', 'profession', 'birth_year', 'birth_year_estimated']] = ['American', 'Roboticist', 1977, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Ryan Graves', ['nationality', 'profession']] = ['American', 'Pilot']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Ryan Schiller', ['nationality', 'profession', 'birth_year', 'birth_year_estimated']] = ['American', 'Entrepreneur', 2000, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Saagar Enjeti', ['nationality', 'profession']] = ['Indian-American', 'Political Commentator']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Sean Carroll', ['nationality', 'profession', 'birth_year', 'death_year']] = ['American', 'Physicist', 1954, 0]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Sean Kelly', ['nationality', 'profession']] = ['American', 'Philosopher']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Sergey Levine', ['nationality', 'profession', 'birth_year']] = ['Russian-American', 'Professor',1987]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Sergey Nazarov', ['nationality', 'profession', 'birth_year', 'birth_year_estimated']] = ['Russian-American', 'Co-Founder', 1988, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Sertac Karaman', ['nationality', 'profession', 'birth_year', 'birth_year_estimated']] = ['Turkish-American', 'Professor', 1985, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Skye Fitzgerald', ['nationality', 'profession']] = ['American', 'Director']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Stephen Kotkin', ['nationality', 'profession']] = ['American', 'Historian']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Stephen Pressfield', ['nationality', 'profession']] = ['American', 'Author']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Stuart Russell', ['nationality', 'profession']] = ['American', 'Professor']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Teddy Atlas', ['nationality', 'profession']] = ['American', 'Martial Arts']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Tim Dillon', ['nationality', 'profession']] = ['American', 'Comedian']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Todd Howard', ['nationality', 'profession']] = ['American', 'Designer']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Tony Fadell', ['nationality', 'profession']] = ['American', 'Engineer']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Vijay Kumar', ['nationality', 'profession']] = ['Indian-American', 'Roboticist']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Walter Isaacson', ['nationality', 'profession']] = ['American', 'Author']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Whitney Cummings', ['nationality', 'profession']] = ['American', 'Comedian']\n",
    "lex_df0.loc[lex_df0['guest'].isin(['Yann LeCun', 'Yann Lecun']), ['nationality', 'profession']] = ['French-American', 'AI Expert']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Yuval Noah', ['nationality', 'profession']] = ['Israeli', 'Historian']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Zev Weinstein', ['nationality', 'profession', 'birth_year']] = ['American', 'Philosopher', 2000]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Nationalism Debate', ['guest', 'nationality', 'profession']] = ['Yaron Brook and Yoram Hazony', 'Israeli', 'Philosopher']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Donald Hoffman', ['nationality', 'profession', 'birth_year', 'death_year']] = ['American', 'Psychologist', 1955, 0]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Brett Johnson', ['nationality', 'profession', 'birth_year', 'death_year']] = ['American', 'Consultant', 1970, 0]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Daniel Kahneman', ['profession', 'birth_year', 'death_year']] = ['Psychologist', 1934, 2024]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Barry Barish', ['profession']] = ['Physicist']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Vladimir Vapnik', ['profession']] = ['Computer Scientist']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Richard Karp', ['profession']] = ['Computer Scientist']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Yannis Pappas', ['profession', 'birth_year', 'death_year']] = ['Comedian', 1976, 0]\n",
    "lex_df0.loc[lex_df0['guest'] == 'James Sexton', ['profession', 'birth_year', 'death_year']] = ['Attorney', 1972, 0]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Jared Kushner', ['profession']] = ['Businessperson']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Jocko Willink', ['profession']] = ['Author']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Richard Wolff', ['nationality', 'profession']] = ['American', 'Economist']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Elon Musk', ['nationality', 'profession']] = ['American-South African', 'Entrepreneur']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Garry Nolan', 'birth_year'] = 1961\n",
    "lex_df0.loc[lex_df0['guest'] == 'Rana el', ['guest', 'nationality', 'profession', 'birth_year']] = ['Rana el Kaliouby', 'Egyptian-American', 'AI Expert', 1978]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Coffeezilla', ['profession', 'birth_year']] = ['YouTuber', 1985]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Yaron Brook', ['profession', 'birth_year']] = ['Writer', 1961]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Andrew Bustamante', ['nationality', 'profession', 'birth_year']] = ['American', 'Former Intelligence Officer', 1981]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Jordan Jonas', ['nationality', 'profession', 'birth_year', 'death_year']] = ['American', 'Survival Expert', 1976, 0]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Shannon Curry', ['birth_year', 'death_year']] = [1986, 0]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Oriol Vinyals', ['birth_year', 'death_year']] = [1983, 0]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Philip Goff', ['nationality', 'profession', 'birth_year', 'death_year', 'birth_year_estimated']] = ['British', 'Philosopher', 1980, 0, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Georges St-Pierre,', ['guest', 'nationality', 'profession', 'birth_year', 'death_year']] = ['Georges St-Pierre', 'Canadian', 'Martial Arts', 1981, 0]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Alex Gladstein', ['birth_year', 'death_year']] = [1984, 0]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Tuomas Sandholm', ['birth_year', 'death_year']] = [1969, 0]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Roger Reaves', ['birth_year', 'death_year']] = [1944, 0]\n",
    "lex_df0.loc[lex_df0['guest'] == 'John Abramson', ['birth_year', 'death_year']] = [1945, 0]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Niels Jorgensen', ['birth_year', 'death_year']] = [1991, 0]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Michael Kearns', ['nationality', 'profession', 'birth_year', 'death_year', 'birth_year_estimated']] = ['American', 'Computer Scientist', 1963, 0, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Gavin Miller', ['nationality', 'profession', 'birth_year', 'death_year', 'birth_year_estimated']] = ['British', 'Computer Scientist', 1960, 0, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Jonathan Reisman', ['birth_year', 'death_year', 'birth_year_estimated']] = [1980, 0, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Peter Wang', ['birth_year', 'death_year', 'birth_year_estimated']] = [1975, 0, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Steve Viscelli', ['nationality', 'profession', 'birth_year', 'death_year', 'birth_year_estimated']] = ['American', 'Sociologist', 1975, 0, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Robert Breedlove', ['nationality', 'profession', 'birth_year', 'death_year', 'birth_year_estimated']] = ['American', 'Entrepreneur', 1985, 0, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Richard Craib', ['nationality', 'profession', 'birth_year', 'death_year', 'birth_year_estimated']] = ['South African', 'Entrepreneur', 1988, 0, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Diana Walsh', ['birth_year', 'death_year', 'birth_year_estimated']] = [1970, 0, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Dmitri Dolgov', ['birth_year', 'death_year', 'birth_year_estimated']] = [1978, 0, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Paola Arlotta', ['birth_year', 'death_year', 'birth_year_estimated']] = [1972, 0, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Robert Proctor', ['nationality', 'profession', 'birth_year', 'death_year']] = ['American', 'Historian', 1954, 0]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Michael I.', ['guest', 'nationality', 'profession']] = ['Michael I. Jordan', 'American', 'Professor']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Paul Rosolie', 'birth_year'] = 1988\n",
    "lex_df0.loc[lex_df0['guest'] == 'Tucker Carlson', 'birth_year'] = 1969\n",
    "lex_df0.loc[lex_df0['guest'] == 'Richard Haier', 'birth_year'] = 1945\n",
    "lex_df0.loc[lex_df0['guest'] == 'Jay Bhattacharya', 'birth_year'] = 1968\n",
    "lex_df0.loc[lex_df0['guest'] == 'Michael Mina', 'birth_year'] = 1969\n",
    "lex_df0.loc[lex_df0['guest'] == 'Rob Reid', 'birth_year'] = 1966\n",
    "lex_df0.loc[lex_df0['guest'] == 'Travis Stevens', 'birth_year'] = 1986\n",
    "lex_df0.loc[lex_df0['guest'] == 'Sheldon Solomon', 'birth_year'] = 1951\n",
    "lex_df0.loc[lex_df0['guest'] == 'Ian Goodfellow', 'birth_year'] = 1985\n",
    "lex_df0.loc[lex_df0['guest'] == 'Grimes', 'birth_year'] = 1988\n",
    "lex_df0.loc[lex_df0['guest'] == 'GothamChess', 'guest'] = 'GothamChess (Levy Rozman)'\n",
    "lex_df0.loc[lex_df0['guest'] == 'David Fravor', ['nationality', 'profession', 'birth_year', 'death_year', 'birth_year_estimated']] = ['American', 'Pilot', 1965, 0, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Jimmy Wales', ['nationality', 'profession', 'birth_year', 'death_year']] = ['American', 'Entrepreneur', 1966, 0]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Kimbal Musk', ['nationality', 'profession', 'birth_year', 'death_year']] = ['American-South African', 'Entrepreneur', 1972, 0]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Tim Urban', ['nationality', 'profession', 'birth_year', 'death_year', 'birth_year_estimated']] = ['American', 'Writer', 1982, 0, True]\n",
    "lex_df0.loc[lex_df0['guest'] == 'Donald Trump', 'profession'] = 'President'\n",
    "lex_df0.loc[lex_df0['guest'] == 'Climate Change', ['guest', 'nationality', 'profession']] = ['Bjørn Lomborg and Andrew Revkin', 'Mixed', 'Mixed']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Rick Spence', ['nationality', 'profession']] = ['American', 'Historian']\n",
    "lex_df0.loc[lex_df0['guest'] == 'Stuart Russell', ['birth_year', 'death_year']] = [1962, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the professions to title case\n",
    "lex_df0['profession'] = lex_df0['profession'].str.strip().str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-arrange the dataframe columns, and drop redundant columns, I'll drop the caption text column\n",
    "lex_df0 = lex_df0[['yt_url', 'number', 'guest', 'nationality', 'profession', 'birth_year', 'death_year', 'birth_year_estimated', 'summary', 'description', 'upload_date', 'duration', 'duration_minutes', 'views', 'likes', 'comments_count', \n",
    "                 'tags', 'top_five_words', 'favorite_count', 'region_restriction', 'thumbnail_url', 'captions_availability']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the data frame into a csv file\n",
    "lex_df0.to_csv('lex fridman podcast episodes.csv', encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
